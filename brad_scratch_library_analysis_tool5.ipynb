{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "#change functions versus objects to camelback\n",
    "#implement clustering tree given distance matrix\n",
    "#think about how to choose threshold (should be between distance \"modes\")\n",
    "#incorporate insert size distribution\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "from scipy.misc import comb\n",
    "import scipy.stats as ss\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import LogNorm\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from collections import Counter\n",
    "from __future__ import division\n",
    "\n",
    "def load_table(sample):\n",
    "    f = open(sample + '.table.txt', 'r')\n",
    "    read_groups = eval(f.readline())\n",
    "    libraries = eval(f.readline())\n",
    "    n_reads = eval(f.readline())\n",
    "    n_reads_removed = eval(f.readline())\n",
    "    table = eval(f.readline())\n",
    "    f.close()\n",
    "    return read_groups, libraries, n_reads, n_reads_removed, table\n",
    "\n",
    "def group_sizes(table, n_groups):\n",
    "    '''Returns vector v where v[i] is count of reads in group i.'''\n",
    "    rg_sizes = np.zeros(n_groups, dtype=int)\n",
    "    for item in table.items():\n",
    "        for i in item[0]:\n",
    "            rg_sizes[i] += item[1]\n",
    "    return rg_sizes\n",
    "\n",
    "def remove_empty_groups(read_groups, libraries, table):\n",
    "    n_groups = len(read_groups)\n",
    "    rg_sizes = group_sizes(table, n_groups)\n",
    "    if np.prod(rg_sizes != 0):\n",
    "        return read_groups, libraries, table\n",
    "    else:\n",
    "        groups = [read_groups[i] for i in range(n_groups) if rg_sizes[i] != 0]\n",
    "        libs = [libraries[i] for i in range(n_groups) if rg_sizes[i] != 0]\n",
    "        new_num_of_old_num = {}\n",
    "        current_num = 0\n",
    "        for i in range(n_groups):\n",
    "            new_num_of_old_num[i] = current_num\n",
    "            if rg_sizes[i] != 0:\n",
    "                current_num += 1\n",
    "        new_table = Counter()\n",
    "        for item in table.items():\n",
    "            new_key = tuple(map(lambda x : new_num_of_old_num[x], list(item[0])))\n",
    "            new_table.update({new_key : item[1]})\n",
    "        return groups, libs, new_table\n",
    "    \n",
    "def library_nums(libraries):\n",
    "    n_groups = len(libraries)\n",
    "    num_of_library = {}\n",
    "    current_num = 0\n",
    "    for i in xrange(n_groups):\n",
    "        if libraries[i] not in num_of_library.keys(): #change to set_default\n",
    "            num_of_library[libraries[i]] = current_num\n",
    "            current_num += 1\n",
    "    return np.array([num_of_library[libraries[i]] for i in xrange(n_groups)])\n",
    "\n",
    "def library_colors(lib_nums):\n",
    "    #lib_color = plt.cm.Set1(lib_nums / (n_libraries + 1))\n",
    "    color_of_num = {0 : 'r', 1 : 'b', 2 : 'g', 3 : 'k', 4 : 'y', 5 : 'm', 6 : 'c'}\n",
    "    return [color_of_num[lib_num % 5] for lib_num in lib_nums]\n",
    "\n",
    "def library_matrix(lib_nums, n_groups):\n",
    "    lib_matrix = np.zeros((n_groups,n_groups), dtype=bool)\n",
    "    for i in xrange(n_groups):\n",
    "        for j in xrange(n_groups):\n",
    "            lib_matrix[i,j] = (lib_nums[i] == lib_nums[j])\n",
    "    return lib_matrix\n",
    "\n",
    "# jaccard similarity. union/intersection. might not be robust to diff conditions. no a priori expectation\n",
    "def overlaps(table, n_groups):\n",
    "    '''Returns matrix where M[i][j] is count of read types in both groups i\n",
    "       and group j (symmetrized)'''\n",
    "    overlap_matrix = np.zeros((n_groups, n_groups))\n",
    "    for item in table.items():\n",
    "        groups = list(set(item[0]))\n",
    "        l = len(groups)\n",
    "        for i in xrange(0,l):\n",
    "            for j in xrange(i,l):\n",
    "                overlap_matrix[groups[i],groups[j]] += item[1]\n",
    "    return (overlap_matrix + overlap_matrix.T) / 2\n",
    "\n",
    "def inner_product(table, n_groups):\n",
    "    '''Returns matrix X^t * X where X[i,j] is count of reads of type i in group j.\n",
    "       Agrees with all_pairs off the diagonal.'''\n",
    "    ip_matrix = np.zeros((n_groups,n_groups))\n",
    "    for item in table.items():\n",
    "        l = len(item[0])\n",
    "        count_vector = np.zeros(n_groups)\n",
    "        for i in xrange(l):\n",
    "            count_vector[item[0][i]] += 1\n",
    "        ip_matrix += np.outer(count_vector, count_vector) * item[1]\n",
    "    return ip_matrix\n",
    "\n",
    "\n",
    "# ABB would be 3 pairs- AB, AB, BB\n",
    "# Retain signal from non-exact pairs. didn't do this as the only metric bc seeing a lot of on-flowcell pad-hopping duplicates, showing up as large duplicate sets, which would dominate here\n",
    "# We only want biological duplicates, and we have been better at marking these. The work yossi and david benj are doing. What's going on from david roazen.\n",
    "# That wasn't ready yet, so he did an exact pairs approach as well.\n",
    "# This one is probably best if you are careful to look at only biological duplicates\n",
    "def all_pairs(table, n_groups):\n",
    "    '''Returns matrix where M[i,j] is count of matching pairs of distinct reads\n",
    "       from groups i and j (symmetrized).'''\n",
    "    ap_matrix = np.zeros((n_groups,n_groups))\n",
    "    for item in table.items():\n",
    "        l = len(item[0])\n",
    "        for i in xrange(l-1):\n",
    "            for j in xrange(i+1,l):\n",
    "                ap_matrix[item[0][i],item[0][j]] += item[1]\n",
    "    return (ap_matrix + np.tril(ap_matrix.T))/2\n",
    "\n",
    "def exact_tuples(table, n_groups, k):\n",
    "    '''Returns array where A[i_1,...i_k] is count of read types that occur\n",
    "       exactly in the groups i_1,...,i_k ascending with repeats.'''\n",
    "    et_array = np.zeros(k*(n_groups,))\n",
    "    for item in table.items():\n",
    "        if len(item[0])==k:\n",
    "            et_array[item[0]] = item[1]\n",
    "    return et_array\n",
    "\n",
    "def exact_pairs(table, n_groups):\n",
    "    '''Returns matrix where M[i,j] is count of read types that occur exactly twice,\n",
    "       once in group i and once in group j (symmetrized).'''\n",
    "    ep_matrix = exact_tuples(table, n_groups, 2)\n",
    "    return (ep_matrix + np.tril(ep_matrix.T))/2\n",
    "\n",
    "def normalize(array):\n",
    "    return array/np.sum(array)\n",
    "\n",
    "# normalize such that diagonals are 1 (so 1 is max self-similarity). off-diag things scaled proportionally\n",
    "def normalize_by_diagonal(matrix):\n",
    "    diag = np.diagonal(matrix)\n",
    "    return matrix / np.sqrt(np.outer(diag, diag))\n",
    "\n",
    "# take the outer product of [pq] with itself\n",
    "# ie [[p^2, pq], [pq, q^2]]\n",
    "# so divide matrix by [[p, rad(pq)], [rad(pq), q]]\n",
    "# so each cell is divided by the total number of elements in it's thing.\n",
    "# most similar to the underlying model\n",
    "def normalize_by_group_size(matrix, group_sizes):\n",
    "    return matrix / np.sqrt(np.outer(group_sizes, group_sizes))\n",
    "\n",
    "def normalize_rows_by_vector(matrix, vector):\n",
    "    return matrix / vector[:, np.newaxis]\n",
    "\n",
    "def overlap_affinity(table, n_groups):\n",
    "    ol_matrix = overlaps(table, n_groups)\n",
    "    ol_affinity = np.zeros((n_groups, n_groups))\n",
    "    for i in xrange(n_groups):\n",
    "        ol_affinity[i,i] = .5\n",
    "        for j in xrange(i+1,n_groups):\n",
    "            ol_affinity[i,j] = 2 * ol_matrix[i,j] / \\\n",
    "                               (ol_matrix[i,i] + ol_matrix[j,j] - 2 * ol_matrix[i,j])\n",
    "    return ol_affinity + ol_affinity.T\n",
    "\n",
    "def exact_pairs_affinity(table, n_groups):\n",
    "    return normalize_by_diagonal(exact_pairs(table, n_groups))\n",
    "\n",
    "def all_pairs_affinity(table, n_groups):\n",
    "    return normalize_by_diagonal(all_pairs(table, n_groups))\n",
    "\n",
    "# Distance in euclidean space between 2 vectrs. each RG is a vector in a space whose dimension is the number of non-zero entries in the union of observed inserts\n",
    "# so, what's teh cosine fo the angle between these 2 vectors\n",
    "# naturally, the diagonal elements will be 1\n",
    "# cosine of angle = (A dot B) / (length A)(length B)\n",
    "\n",
    "# BUT our data isn't in the form of these vectors. So we count the AB pairs.\n",
    "# Recording each time he sees some combination of 2 numbers.\n",
    "\n",
    "# suffers the same issue as jaccard- what is your expectation. this is why all pairs and exact pairs only viable.\n",
    "def L2_affinity(table, n_groups):\n",
    "    return normalize_by_diagonal(inner_product(table, n_groups))\n",
    "\n",
    "def exact_pairs_affinity2(table, n_groups, rg_sizes):\n",
    "    return normalize(normalize_by_group_size(exact_pairs(table, n_groups),rg_sizes))\n",
    "\n",
    "def all_pairs_affinity2(table, n_groups, rg_sizes):\n",
    "    return normalize(normalize_by_group_size(all_pairs(table, n_groups),rg_sizes))\n",
    "\n",
    "def zero_diag(matrix):\n",
    "    new_matrix = matrix.copy()\n",
    "    for i in xrange(matrix.shape[0]):\n",
    "        new_matrix[i,i] = 0\n",
    "    return new_matrix\n",
    "\n",
    "def multiplicity_matrix(table, n_groups):\n",
    "    '''Returns M with M_ij count of j-tuples in group i'''\n",
    "    max_mult =  max(map(len,table.keys()))\n",
    "    mult_matrix = np.zeros((n_groups, max_mult + 1), dtype=int)\n",
    "    for i in xrange(n_groups):\n",
    "        mult_vector = multiplicity_vector(subtable(table,i))\n",
    "        for j in xrange(len(mult_vector)):\n",
    "            mult_matrix[i,j] = mult_vector[j]\n",
    "    return mult_matrix\n",
    "\n",
    "def multiplicity_vector(table):\n",
    "    '''Returns v with v_j count of j-tuples in table'''\n",
    "    max_mult =  max(map(len,table.keys()))\n",
    "    mult_vector = np.zeros(max_mult + 1, dtype=int)\n",
    "    for item in table.items():\n",
    "        mult_vector[len(item[0])] += item[1]   \n",
    "    return mult_vector\n",
    "\n",
    "def subtable(table, i):\n",
    "    '''Returns subtable for group i'''\n",
    "    group_table = Counter()\n",
    "    for item in table.items():\n",
    "        mult = item[0].count(i)\n",
    "        if mult > 0:\n",
    "            group_table.update({(i,)*mult : item[1]})\n",
    "    return group_table\n",
    "\n",
    "def plot_matrix_rows(matrix, title = 'Matrix rows'):\n",
    "    max_mult = np.sum(np.sum(matrix,axis=0) > 0) - 1\n",
    "    for i in xrange(n_groups):\n",
    "        plt.semilogy(range(1, max_mult + 3), matrix[i,1:max_mult + 3],\n",
    "                 label=i, color = plt.cm.Set1(i/n_groups))\n",
    "    #plt.yscale('log')\n",
    "    plt.ylim(np.min(matrix), 10 * np.max(matrix))\n",
    "    plt.title(title)\n",
    "    plt.legend(title='RG')\n",
    "    plt.show() #change ticks to integers only\n",
    "\n",
    "def plot_matrix(matrix, title='Matrix', vmax=None):\n",
    "    n, m = matrix.shape\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "    plt.pcolor(matrix, edgecolor='k', cmap = plt.cm.Blues, vmin=0, vmax=vmax)\n",
    "    plt.colorbar()\n",
    "    ax.set_xticks(np.arange(n)+0.5)\n",
    "    ax.set_yticks(np.arange(m)+0.5)\n",
    "    ax.set_xticklabels(np.arange(n))\n",
    "    ax.set_yticklabels(np.arange(m))\n",
    "    ax.set_title(title)\n",
    "    ax.invert_yaxis()\n",
    "    plt.show()\n",
    "\n",
    "def normalize_to_Markov(matrix):\n",
    "    row_sums = matrix.sum(axis=1)\n",
    "    return matrix / row_sums[:, np.newaxis]\n",
    "    \n",
    "def eigen(affinity):\n",
    "    #change to computer for symmetrix matrix and convert?\n",
    "    #is absolute value necessary? correct? won't fractoinal powers cause trouble?\n",
    "    evals, evecs = np.linalg.eig(normalize_to_Markov(affinity))\n",
    "    order = np.argsort(np.abs(evals))[::-1]\n",
    "    return evals[order], evecs[:,order]\n",
    "\n",
    "def diffusion_distances(evals, evecs, t = None):\n",
    "    if not t:\n",
    "        t = 1 / (1-evals[1])\n",
    "    n_groups = len(evals)\n",
    "    scaled_evecs = evecs[:,1:] * evals[1:]**t  #check that this works as expected\n",
    "    dd_matrix = np.zeros((n_groups,n_groups))\n",
    "    for i in xrange(n_groups):\n",
    "        dd_matrix[i,i]=0\n",
    "        for j in xrange(i+1, n_groups):\n",
    "            difference = scaled_evecs[i,:] - scaled_evecs[j,:]\n",
    "            dd_matrix[i,j] = np.sqrt(np.dot(difference,difference))\n",
    "    return dd_matrix + dd_matrix.T\n",
    "\n",
    "def plot_diffusion(evals, evecs, t=None, bound=None, title='Diffusion', color=None):\n",
    "    if not t:\n",
    "        t = 1 / (1-evals[1])\n",
    "    x = evecs[:,1]*(evals[1]**t)\n",
    "    y = evecs[:,2]*(evals[2]**t)\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "    lib_nums = library_nums(libraries)\n",
    "    ax.scatter(x, y, color=color)\n",
    "    ax.set_title(title)\n",
    "    if bound:\n",
    "        ax.set_xlim(-bound,bound)\n",
    "        ax.set_ylim(-bound,bound)\n",
    "    plt.show()\n",
    "\n",
    "def plot_diffusion_3d(evals, evecs, t=None, bound=None, title='Diffusion', color=None):\n",
    "    if not t:\n",
    "        t = 1 / (1-evals[1])\n",
    "    x = evecs[:,1]*(evals[1]**t)\n",
    "    y = evecs[:,2]*(evals[2]**t)\n",
    "    z = evecs[:,3]*(evals[3]**t)\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111,projection=\"3d\")\n",
    "    ax.scatter3D(x, y, z, color = color)\n",
    "    ax.set_title(title)\n",
    "    if bound:\n",
    "        ax.set_xlim3d(-bound,bound)\n",
    "        ax.set_ylim3d(-bound,bound)\n",
    "        ax.set_zlim3d(-bound,bound)\n",
    "    plt.show()\n",
    "\n",
    "def scatter_affinities(affinities, lib_matrices, pair_colors, log_scale = False, title='Scatter'):   \n",
    "    fig = plt.figure(figsize=(10,8))\n",
    "    xs = np.arange(len(pair_colors))\n",
    "    plt.scatter(xs, affinities, s=2, color = pair_colors)\n",
    "    plt.title(title)\n",
    "    plt.ylim(1e-6,1)\n",
    "    if log_scale == True:\n",
    "        plt.yscale('log')\n",
    "    for i in xs:\n",
    "        if lib_matrices[i] == 3:\n",
    "            plt.axvline(x=i,ls='-',alpha = .5,c='g',linewidth=1,)\n",
    "    plt.show()\n",
    "    \n",
    "def plot_graph(matrix, threshold, color=None, complement = False):\n",
    "    print 'Threshold =', threshold #include this in title\n",
    "    n_groups = matrix.shape[0]\n",
    "    labels = dict(zip(range(n_groups),range(n_groups)))\n",
    "    if complement:\n",
    "        G = nx.Graph(matrix < threshold)\n",
    "    else:\n",
    "        G = nx.Graph(matrix >= threshold)\n",
    "    pos=nx.spring_layout(G)\n",
    "    nx.draw_networkx_nodes(G,pos,node_color=color)\n",
    "    nx.draw_networkx_edges(G,pos)\n",
    "    nx.draw_networkx_labels(G,pos,labels=labels,font_color='w',font_size=16)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'load_table' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-52ba90a2c7d3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0msample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'C1705'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mgroups\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlibs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_reads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_reads_removed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_table\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mread_groups\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlibraries\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mremove_empty_groups\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgroups\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlibs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'load_table' is not defined"
     ]
    }
   ],
   "source": [
    "#samples = ['G9166', 'G13337','C669','C322','C1688','C1700','C661','C1699','C1705','C1704','C1811']\n",
    "#sample = 'C1700'\n",
    "#sample = 'C1688'\n",
    "sample = 'C1705'\n",
    "\n",
    "groups, libs, n_reads, n_reads_removed, table = load_table(sample)\n",
    "read_groups, libraries, table = remove_empty_groups(groups, libs, table)\n",
    "\n",
    "n_groups = len(read_groups)\n",
    "rg_sizes = group_sizes(table, n_groups)\n",
    "lib_nums = library_nums(libraries)\n",
    "n_libraries = np.max(lib_nums)\n",
    "lib_matrix = library_matrix(lib_nums, n_groups)\n",
    "lib_color = library_colors(lib_nums)\n",
    "ol_affinity = overlap_affinity(table, n_groups)\n",
    "mult_matrix = multiplicity_matrix(table, n_groups)\n",
    "mult_matrix2 = normalize_rows_by_vector(mult_matrix, rg_sizes)\n",
    "el2_affinity = L2_affinity(table, n_groups)\n",
    "angle_matrix = np.arccos(el2_affinity)\n",
    "ap_affinity = all_pairs_affinity(table, n_groups)\n",
    "ap_affinity2 = all_pairs_affinity2(table, n_groups, rg_sizes)\n",
    "ep_affinity = exact_pairs_affinity(table, n_groups)\n",
    "ep_affinity2 = exact_pairs_affinity2(table, n_groups, rg_sizes)\n",
    "evals1, evecs1 = eigen(el2_affinity)\n",
    "evals2, evecs2 = eigen(ap_affinity)\n",
    "dd_matrix1 = diffusion_distances(evals1,evecs1)\n",
    "dd_matrix2 = diffusion_distances(evals2,evecs2)\n",
    "\n",
    "print rg_sizes\n",
    "print np.sum(rg_sizes)\n",
    "print evals1\n",
    "print evals2\n",
    "plot_matrix_rows(mult_matrix, title='Number of n-tuples for each n by group')\n",
    "#plot_matrix_rows(mult_matrix2, title='Number of n-tuples for each n by group, scaled')\n",
    "plot_matrix(zero_diag(ol_affinity), title='Overlap affinity (Jacard distance)')\n",
    "plot_matrix(zero_diag(el2_affinity), title='L2 affinity')\n",
    "plot_matrix(zero_diag(ap_affinity), title='All pairs affinity')\n",
    "#plot_matrix(zero_diag(ap_affinity2), title='All pairs affinity 2')\n",
    "plot_matrix(zero_diag(ep_affinity), title='Exact pairs affinity')\n",
    "#plot_matrix(zero_diag(ep_affinity2), title='Exact pairs affinity 2')\n",
    "plot_diffusion(evals1,evecs1,title='L2 diffusion',color=lib_color)\n",
    "plot_diffusion(evals2,evecs2,title='All pairs diffusion',color=lib_color)\n",
    "plot_diffusion_3d(evals1,evecs1,title='L2 diffusion',color=lib_color)\n",
    "plot_diffusion_3d(evals2,evecs2,title='All pairs diffusion',color=lib_color)\n",
    "plot_graph(ap_affinity, .01, color=lib_color)\n",
    "plot_graph(ap_affinity, .02, color=lib_color)\n",
    "plot_graph(ap_affinity, .05, color=lib_color)\n",
    "plot_graph(ap_affinity, .1, color=lib_color)\n",
    "plot_graph(ap_affinity, .2, color=lib_color)\n",
    "plot_graph(ap_affinity, .3, color=lib_color)\n",
    "plot_graph(ap_affinity, .4, color=lib_color)\n",
    "plot_graph(dd_matrix1, .001, color=lib_color, complement = True)\n",
    "plot_graph(dd_matrix1, .003, color=lib_color, complement = True)\n",
    "plot_graph(dd_matrix1, .01, color=lib_color, complement = True)\n",
    "plot_graph(dd_matrix1, .03, color=lib_color, complement = True)\n",
    "plot_graph(dd_matrix1, .1, color=lib_color, complement = True)\n",
    "plot_graph(dd_matrix1, .3, color=lib_color, complement = True)\n",
    "print read_groups\n",
    "print libraries\n",
    "\n",
    "#print multiplicity_vector(table)\n",
    "#for item in table.items():\n",
    "#    if len(item[0])>20:\n",
    "#        print item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "samples = ['G9166', 'G13337', 'C669','C322','C1688','C1700','C661','C1699','C1705','C1704','C1811'] #removed C669\n",
    "n_samples = len(samples)\n",
    "\n",
    "ol_affinity_of_sample = {}\n",
    "el2_affinity_of_sample = {}\n",
    "ap_affinity_of_sample = {}\n",
    "ep_affinity_of_sample = {}\n",
    "lib_matrix_of_sample = {}\n",
    "dd_matrix1_of_sample = {}\n",
    "dd_matrix2_of_sample = {}\n",
    "\n",
    "for sample in samples:\n",
    "    groups, libs, n_reads, n_reads_removed, table = load_table(sample)\n",
    "    read_groups, libraries, table = remove_empty_groups(groups, libs, table)\n",
    "    n_groups = len(read_groups)\n",
    "    rg_sizes = group_sizes(table, n_groups)\n",
    "    lib_nums = library_nums(libraries)\n",
    "    n_libraries = np.max(lib_nums)\n",
    "    lib_color = library_colors(lib_nums)\n",
    "    lib_matrix = library_matrix(lib_nums, n_groups)\n",
    "    ol_affinity = overlap_affinity(table, n_groups)\n",
    "    mult_matrix = multiplicity_matrix(table, n_groups)\n",
    "    mult_matrix2 = normalize_rows_by_vector(mult_matrix, rg_sizes)\n",
    "    el2_affinity = L2_affinity(table, n_groups)\n",
    "    angle_matrix = np.arccos(el2_affinity)\n",
    "    ap_affinity = all_pairs_affinity(table, n_groups)\n",
    "    ap_affinity2 = all_pairs_affinity2(table, n_groups, rg_sizes)\n",
    "    ep_affinity = exact_pairs_affinity(table, n_groups)\n",
    "    ep_affinity2 = exact_pairs_affinity2(table, n_groups, rg_sizes)\n",
    "    evals1, evecs1 = eigen(el2_affinity)\n",
    "    evals2, evecs2 = eigen(ap_affinity)\n",
    "    dd_matrix1 = diffusion_distances(evals1,evecs1)\n",
    "    dd_matrix2 = diffusion_distances(evals2,evecs2)\n",
    "    \n",
    "    ol_affinity_of_sample[sample] = ol_affinity\n",
    "    el2_affinity_of_sample[sample] = el2_affinity\n",
    "    ap_affinity_of_sample[sample] = ap_affinity\n",
    "    ep_affinity_of_sample[sample] = ep_affinity\n",
    "    lib_matrix_of_sample[sample] = lib_matrix\n",
    "    dd_matrix1_of_sample[sample] = dd_matrix1\n",
    "    dd_matrix2_of_sample[sample] = dd_matrix2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#ap_affinity_of_sample\n",
    "ol_affinities = np.array([1,1,1])\n",
    "el2_affinities = np.array([1,1,1])\n",
    "ap_affinities = np.array([1,1,1])\n",
    "ep_affinities = np.array([1,1,1])\n",
    "dd_matrices1 = np.array([1,1,1])\n",
    "dd_matrices2 = np.array([1,1,1])\n",
    "lib_matrices = np.array([3,2,2])\n",
    "for sample in samples:\n",
    "    ol_affinity = ol_affinity_of_sample[sample]\n",
    "    el2_affinity = el2_affinity_of_sample[sample]\n",
    "    ap_affinity = ap_affinity_of_sample[sample]\n",
    "    ep_affinity = ep_affinity_of_sample[sample]\n",
    "    dd_matrix1 = dd_matrix1_of_sample[sample]\n",
    "    dd_matrix2 = dd_matrix2_of_sample[sample]\n",
    "    lib_matrix = lib_matrix_of_sample[sample]\n",
    "    i_triu1 = np.triu_indices(ap_affinity.shape[0], k=1)\n",
    "    ol_affinities = np.concatenate((ol_affinities, ol_affinity[i_triu1],np.array([1,1,1,1,1])))\n",
    "    el2_affinities = np.concatenate((el2_affinities, el2_affinity[i_triu1],np.array([1,1,1,1,1])))\n",
    "    ap_affinities = np.concatenate((ap_affinities, ap_affinity[i_triu1],np.array([1,1,1,1,1])))\n",
    "    ep_affinities = np.concatenate((ep_affinities, ep_affinity[i_triu1],np.array([1,1,1,1,1])))\n",
    "    dd_matrices1 = np.concatenate((dd_matrices1, dd_matrix1[i_triu1],np.array([1,1,1,1,1])))\n",
    "    dd_matrices2 = np.concatenate((dd_matrices2, dd_matrix2[i_triu1],np.array([1,1,1,1,1])))\n",
    "    lib_matrices = np.concatenate((lib_matrices, lib_matrix[i_triu1],np.array([2,2,3,2,2])))\n",
    "    \n",
    "def bool_to_color(x):\n",
    "    if x == True:\n",
    "        return 'b'\n",
    "    elif x == False:\n",
    "        return 'r'\n",
    "    else:\n",
    "        return 'w'\n",
    "\n",
    "pair_colors = np.vectorize(bool_to_color)(lib_matrices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "log_scale = False\n",
    "scatter_affinities(ol_affinities, lib_matrices, pair_colors, title ='Overlap', log_scale=log_scale)\n",
    "scatter_affinities(el2_affinities, lib_matrices, pair_colors, title ='L2', log_scale=log_scale)\n",
    "scatter_affinities(ap_affinities, lib_matrices, pair_colors, title ='All pairs', log_scale=log_scale)\n",
    "scatter_affinities(ep_affinities, lib_matrices, pair_colors, title ='Exact pairs', log_scale=log_scale)\n",
    "scatter_affinities(dd_matrices1, lib_matrices, pair_colors, title ='Diffusion distance from L2', log_scale=log_scale)\n",
    "scatter_affinities(dd_matrices2, lib_matrices, pair_colors, title ='Diffusion distance from all pairs', log_scale=log_scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.hist(ap_affinities, bins=np.arange(0,1,.001))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Investigate empirical and expected distribution of multiplicites\n",
    "#e.g., how many values occur i times for each i\n",
    "#Here we assume a uniform distribution, later should try less entropy\n",
    "\n",
    "#set and advance seed\n",
    "try:\n",
    "    seed += 1\n",
    "except:\n",
    "    seed = 0\n",
    "rs = np.random.RandomState(seed)\n",
    "\n",
    "n_dist = 10000000\n",
    "n_sample = 3684904\n",
    "\n",
    "sample = rs.multinomial(n_sample, np.ones(n_dist)/n_dist)\n",
    "max_mult = np.max(sample)\n",
    "mult_array_emp = np.array([np.sum(sample == i) for i in range(max_mult+1)])\n",
    "mult_array_exp = n_dist * ss.binom(n_sample, 1/n_dist).pmf(np.arange(max_mult+1))\n",
    "#def mult_exp(n_dist, n_sample, i):  #this is equivalent\n",
    "#    return comb(n_sample,i) * (1/n_dist)**(i-1) * (1 - 1/n_dist)**(n_sample - i)\n",
    "#mult_array_exp = np.array([n_dist * (1-1/n_dist)**n_sample] + [mult_exp(n_dist, n_sample, i) for i in range(1,max_mult+1)])\n",
    "\n",
    "np.set_printoptions(precision=1)\n",
    "\n",
    "print mult_array_emp\n",
    "print mult_array_exp\n",
    "\n",
    "#plt.scatter(range(max_mult + 1), mult_array_emp)\n",
    "plt.scatter(range(max_mult + 1), mult_array_exp, color = 'r')\n",
    "plt.yscale('log')\n",
    "plt.ylim(.1,10*max(mult_array_emp))\n",
    "plt.title('Number of n-tuples for each n')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.set_printoptions(precision = 6)\n",
    "print ap_affinity / el2_affinity #quite different\n",
    "print ap_affinity2 / el2_affinity #very similar, only difference is that size of read group is not same as length of read group'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print ap_affinity\n",
    "print el2_affinity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for library in libraries:\n",
    "    print library\n",
    "\n",
    "for group in groups:\n",
    "    print group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print all_pairs.__doc__\n",
    "print all_pairs.__name__\n",
    "print all_pairs.__defaults__\n",
    "print all_pairs.__code__\n",
    "#print all_pairs.__globals__\n",
    "print all_pairs.__dict__\n",
    "print all_pairs.__closure__\n",
    "\n",
    "print plot_matrix.__doc__\n",
    "print plot_matrix.__name__\n",
    "print plot_matrix.__defaults__\n",
    "print plot_matrix.__code__\n",
    "#print plot_matrix.__globals__\n",
    "print plot_matrix.__dict__\n",
    "print plot_matrix.__closure__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "np.set_printoptions(precision=1, suppress=True)\n",
    "\n",
    "print all_pairs(table, n_groups)\n",
    "print inner_product(table, n_groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!ls -lathr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(table.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(table.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bradscratch stuff below here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Source data from printouts. I don't have the original data\n",
    "table = {(5,): 140358, (3,): 139360, (1,): 124943, (4,): 123598, (2,): 122481, (0,): 108269, (5, 5): 13190, (3, 3): 12908, (1, 1): 11659, (4, 4): 11056, (2, 2): 10878, (0, 0): 9780, (3, 5): 5807, (1, 3): 5595, (2, 4): 5338, (0, 2): 5116, (1, 5): 2240, (0, 4): 2197, (3, 3, 3): 1617, (5, 5, 5): 1604, (1, 1, 1): 1449, (4, 4, 4): 1297, (2, 2, 2): 1253, (3, 3, 5): 1148, (0, 0, 0): 1143, (3, 5, 5): 1127, (1, 3, 3): 1066, (2, 4, 4): 1027, (1, 1, 3): 992, (2, 2, 4): 974, (0, 2, 2): 968, (1, 3, 5): 932, (0, 2, 4): 929, (0, 0, 2): 855, (2, 3): 563, (4, 5): 522, (0, 1): 488, (1, 5, 5): 446, (0, 4, 4): 438, (0, 0, 4): 430, (1, 1, 5): 368, (1, 3, 3, 5): 310, (3, 3, 5, 5): 267, (1, 3, 5, 5): 241, (5, 5, 5, 5): 240, (2, 2, 4, 4): 235, (1, 1, 3, 3): 233, (3, 3, 3, 5): 232, (0, 2, 2, 4): 228, (0, 0, 2, 4): 212, (3, 3, 3, 3): 209, (1, 1, 1, 1): 207, (0, 2, 4, 4): 205, (3, 5, 5, 5): 204, (1, 1, 3, 5): 202, (1, 3, 3, 3): 195, (0, 0, 2, 2): 179, (1, 1, 1, 3): 178, (4, 4, 4, 4): 175, (2, 4, 4, 4): 172, (0, 2, 2, 2): 172, (2, 2, 2, 4): 165, (2, 2, 2, 2): 155, (0, 0, 0, 0): 140, (0, 0, 0, 2): 137, (1, 1, 5, 5): 110, (0, 0, 4, 4): 96, (4, 5, 5): 72, (1, 3, 3, 5, 5): 71, (0, 1, 1): 69, (0, 0, 2, 2, 4): 69, (1, 1, 3, 3, 5): 64, (0, 4, 4, 4): 64, (2, 3, 3): 63, (0, 0, 2, 4, 4): 62, (3, 3, 3, 5, 5): 61, (1, 5, 5, 5): 61, (0, 0, 0, 4): 58, (3, 3, 5, 5, 5): 57, (1, 1, 3, 5, 5): 57, (0, 2, 2, 4, 4): 55, (2, 2, 3): 53, (4, 4, 5): 52, (0, 2, 2, 2, 4): 51, (1, 3, 5, 5, 5): 51, (3, 4): 51, (1, 1, 1, 3, 3): 51, (2, 5): 48, (1, 3, 3, 3, 5): 47, (0, 0, 1): 47, (0, 3): 46, (1, 1, 1, 5): 45, (1, 1, 3, 3, 3): 45, (1, 3, 3, 3, 3): 43, (0, 0, 0, 2, 4): 42, (2, 2, 4, 4, 4): 42, (1, 2): 42, (1, 1, 1, 3, 5): 41, (2, 2, 2, 4, 4): 39, (3, 5, 5, 5, 5): 38, (0, 0, 0, 2, 2): 37, (0, 2, 4, 4, 4): 37, (3, 3, 3, 3, 3): 36, (0, 2, 2, 2, 2): 30, (3, 3, 3, 3, 5): 30, (5, 5, 5, 5, 5): 29, (2, 4, 4, 4, 4): 27, (0, 0, 2, 2, 2): 26, (1, 1, 1, 1, 3): 26, (0, 0, 0, 0, 0): 24, (0, 0, 4, 4, 4): 24, (0, 0, 0, 0, 2): 23, (4, 4, 4, 4, 4): 23, (1, 1, 1, 1, 1): 22, (2, 2, 2, 2, 2): 22, (1, 1, 3, 5, 5, 5): 22, (2, 2, 2, 2, 4): 21, (1, 1, 3, 3, 5, 5): 20, (1, 1, 3, 3, 3, 5): 19, (1, 1, 1, 1, 3, 3): 19, (3, 4, 5): 18, (0, 0, 2, 2, 4, 4): 17, (1, 1, 1, 3, 5, 5): 17, (1, 2, 3): 17, (1, 3, 3, 3, 5, 5): 16, (1, 1, 1, 5, 5): 16, (1, 1, 5, 5, 5): 15, (0, 2, 2, 4, 4, 4): 15, (0, 2, 2, 2, 4, 4): 14, (1, 3, 3, 5, 5, 5): 14, (0, 0, 2, 2, 2, 4): 14, (3, 3, 3, 5, 5, 5): 14, (3, 3, 5, 5, 5, 5): 14, (2, 3, 5): 13, (0, 0, 0, 4, 4): 13, (1, 1, 1, 3, 3, 5): 12, (2, 4, 5): 12, (2, 3, 4): 12, (0, 1, 2): 12, (4, 5, 5, 5): 12, (3, 3, 3, 3, 5, 5): 11, (2, 2, 3, 3): 11, (1, 1, 1, 3, 3, 3): 11, (0, 0, 2, 4, 4, 4): 11, (0, 0, 2, 2, 2, 2): 11, (1, 3, 3, 3, 5, 5, 5): 10, (1, 3, 3, 3, 3, 5): 10, (1, 5, 5, 5, 5): 10, (1, 1, 1, 1, 5): 10, (1, 1, 1, 1, 3, 5): 10, (0, 1, 1, 1): 10, (1, 1, 3, 3, 3, 3): 9, (0, 4, 4, 4, 4): 9, (0, 2, 3): 9, (2, 2, 2, 3): 9, (0, 0, 0, 2, 4, 4): 9, (0, 2, 2, 2, 2, 4): 8, (0, 1, 2, 2): 8, (5, 5, 5, 5, 5, 5): 8, (4, 4, 5, 5): 8, (1, 3, 3, 3, 3, 3): 8, (4, 4, 4, 5): 8, (0, 1, 3): 8, (0, 0, 0, 2, 2, 4, 4): 7, (0, 1, 2, 3): 7, (0, 0, 0, 0, 2, 2): 7, (2, 2, 2, 4, 4, 4): 7, (1, 1, 3, 3, 5, 5, 5): 7, (1, 2, 2): 7, (0, 0, 0, 1): 7, (0, 0, 0, 2, 2, 2): 7, (0, 0, 0, 2, 2, 4): 7, (0, 0, 0, 0, 4): 7, (0, 0, 0, 0, 2, 4): 7, (1, 4): 7, (1, 3, 5, 5, 5, 5): 7, (0, 2, 2, 2, 4, 4, 4): 6, (1, 1, 1, 3, 5, 5, 5): 6, (2, 2, 5): 6, (1, 1, 1, 1, 3, 5, 5): 6, (0, 2, 4, 4, 4, 4): 6, (3, 3, 4): 6, (2, 5, 5): 6, (1, 1, 1, 1, 1, 3): 6, (2, 2, 2, 2, 4, 4): 6, (0, 0, 1, 1): 6, (1, 1, 1, 1, 1, 3, 3): 5, (1, 1, 3, 5, 5, 5, 5): 5, (0, 0, 0, 0, 0, 2): 5, (1, 1, 1, 1, 1, 1): 5, (0, 0, 3): 5, (0, 0, 0, 0, 2, 2, 4): 5, (1, 1, 5, 5, 5, 5): 5, (2, 4, 4, 5): 5, (0, 0, 0, 0, 4, 4): 5, (1, 1, 1, 3, 3, 3, 3): 5, (1, 1, 2): 5, (3, 4, 4): 5, (0, 0, 2, 2, 2, 4, 4, 4): 4, (1, 1, 1, 3, 3, 5, 5): 4, (0, 5): 4, (1, 2, 5): 4, (1, 1, 1, 5, 5, 5): 4, (2, 3, 3, 5, 5): 4, (2, 3, 5, 5): 4, (3, 5, 5, 5, 5, 5): 4, (4, 4, 4, 4, 4, 4): 4, (3, 3, 3, 3, 5, 5, 5): 4, (0, 2, 2, 3): 4, (1, 1, 3, 3, 3, 5, 5): 4, (5, 5, 5, 5, 5, 5, 5): 4, (0, 5, 5): 3, (0, 2, 2, 2, 2, 2, 4): 3, (0, 2, 5): 3, (0, 0, 0, 4, 4, 4): 3, (0, 0, 4, 4, 4, 4): 3, (3, 3, 3, 5, 5, 5, 5): 3, (1, 1, 3, 3, 3, 5, 5, 5): 3, (2, 2, 2, 2, 4, 4, 4): 3, (2, 3, 3, 5): 3, (0, 3, 3): 3, (0, 2, 2, 2, 2, 2, 4, 4): 3, (0, 0, 2, 2, 4, 4, 4): 3, (2, 2, 2, 2, 2, 2): 3, (1, 1, 3, 3, 3, 3, 5): 3, (3, 3, 4, 5): 3, (0, 0, 0, 2, 2, 4, 4, 4): 3, (1, 3, 3, 5, 5, 5, 5): 3, (1, 3, 3, 3, 3, 3, 5): 3, (2, 2, 3, 4): 3, (0, 1, 3, 3): 3, (1, 1, 1, 3, 3, 3, 5, 5): 3, (1, 1, 1, 1, 3, 3, 5): 3, (1, 3, 3, 3, 3, 3, 3): 3, (1, 1, 3, 3, 3, 3, 3): 3, (2, 3, 3, 3): 3, (2, 4, 4, 4, 4, 4): 3, (1, 3, 3, 3, 3, 5, 5): 3, (2, 2, 4, 4, 4, 4): 3, (1, 4, 4): 2, (4, 5, 5, 5, 5): 2, (1, 3, 3, 5, 5, 5, 5, 5): 2, (3, 3, 3, 3, 3, 5): 2, (4, 4, 4, 5, 5): 2, (1, 1, 1, 1, 1, 3, 5, 5): 2, (0, 0, 0, 0, 0, 4): 2, (3, 4, 4, 5): 2, (2, 2, 3, 3, 3): 2, (2, 2, 3, 5): 2, (0, 0, 2, 2, 2, 2, 4, 4): 2, (1, 1, 4): 2, (0, 2, 3, 3): 2, (1, 1, 1, 1, 3, 3, 5, 5, 5): 2, (1, 1, 1, 3, 5, 5, 5, 5): 2, (2, 2, 2, 2, 2, 2, 4): 2, (0, 0, 0, 0, 0, 2, 4): 2, (0, 0, 2, 2, 2, 4, 4): 2, (0, 0, 0, 0, 2, 2, 2, 2): 2, (1, 1, 1, 3, 3, 3, 3, 5, 5): 2, (2, 2, 2, 2, 2, 4): 2, (0, 1, 1, 3): 2, (0, 2, 2, 2, 2, 4, 4, 4): 2, (0, 0, 0, 0, 2, 2, 4, 4): 2, (4, 4, 5, 5, 5): 2, (3, 4, 4, 4): 2, (2, 3, 3, 4, 5): 2, (0, 3, 3, 5): 2, (0, 2, 3, 4): 2, (2, 3, 4, 5, 5): 2, (1, 1, 1, 1, 1, 5): 2, (0, 0, 0, 2, 2, 2, 4): 2, (0, 0, 2, 2, 2, 2, 2): 2, (1, 1, 1, 1, 3, 5, 5, 5): 2, (1, 3, 5, 5, 5, 5, 5): 2, (0, 0, 2, 2, 2, 2, 2, 4): 2, (0, 0, 0, 0, 2, 4, 4): 2, (0, 0, 0, 1, 2): 2, (3, 3, 3, 3, 3, 3, 5): 2, (3, 3, 3, 3, 3, 3): 2, (3, 3, 3, 3, 3, 5, 5): 2, (0, 2, 2, 2, 2, 2, 2): 2, (1, 2, 3, 3): 2, (0, 0, 1, 3): 2, (1, 1, 1, 1, 5, 5): 2, (0, 0, 0, 2, 2, 2, 2): 2, (2, 3, 3, 4): 2, (3, 3, 3, 4): 2, (1, 1, 2, 3): 2, (3, 3, 3, 3, 3, 3, 3): 2, (0, 0, 2, 2, 2, 2, 4): 2, (0, 0, 1, 2): 2, (1, 3, 3, 4): 2, (1, 1, 1, 2): 2, (0, 0, 0, 2, 4, 4, 4): 2, (1, 1, 1, 1, 1, 1, 3): 2, (1, 1, 3, 3, 3, 3, 3, 5, 5): 2, (2, 4, 5, 5, 5): 2, (0, 0, 0, 0, 2, 2, 2): 2, (3, 3, 5, 5, 5, 5, 5): 2, (0, 0, 0, 2, 2, 2, 2, 4): 1, (2, 3, 3, 5, 5, 5, 5, 5): 1, (1, 1, 3, 3, 3, 3, 5, 5): 1, (0, 0, 2, 2, 2, 3): 1, (2, 3, 3, 3, 3, 4, 5): 1, (0, 0, 2, 2, 3): 1, (0, 1, 1, 3, 3, 3, 5): 1, (0, 2, 3, 3, 5): 1, (2, 2, 2, 4, 5): 1, (1, 2, 4): 1, (0, 0, 2, 2, 2, 2, 2, 4, 4): 1, (2, 2, 4, 4, 4, 4, 4): 1, (0, 1, 2, 2, 2, 3): 1, (0, 1, 1, 2): 1, (1, 1, 1, 1, 1, 3, 3, 5): 1, (0, 1, 1, 5): 1, (3, 3, 3, 4, 4): 1, (0, 1, 1, 1, 1, 1): 1, (0, 0, 1, 4): 1, (0, 0, 0, 1, 1, 1, 3, 3): 1, (2, 2, 3, 4, 5): 1, (1, 3, 3, 3, 5, 5, 5, 5): 1, (1, 4, 4, 5, 5): 1, (1, 1, 2, 5, 5): 1, (0, 2, 3, 3, 3): 1, (1, 1, 1, 1, 3, 3, 3, 5): 1, (3, 3, 3, 4, 5): 1, (0, 2, 2, 2, 2, 2): 1, (1, 1, 1, 3, 3, 3, 5, 5, 5): 1, (1, 1, 1, 1, 5, 5, 5): 1, (3, 4, 5, 5, 5): 1, (1, 1, 2, 4, 5, 5): 1, (1, 1, 1, 3, 3, 3, 3, 3, 5): 1, (0, 0, 0, 3): 1, (2, 3, 4, 4, 4): 1, (4, 4, 4, 4, 5): 1, (1, 2, 2, 2, 2): 1, (1, 1, 2, 2, 4): 1, (1, 2, 3, 4, 4): 1, (3, 3, 3, 3, 5, 5, 5, 5): 1, (2, 3, 4, 5): 1, (0, 0, 0, 2, 2, 2, 2, 2): 1, (2, 3, 3, 3, 4, 5): 1, (1, 1, 3, 3, 3, 3, 3, 5, 5, 5): 1, (0, 1, 1, 2, 2): 1, (1, 1, 1, 1, 1, 5, 5): 1, (3, 4, 4, 5, 5, 5): 1, (1, 1, 3, 3, 5, 5, 5, 5): 1, (0, 2, 3, 4, 5): 1, (0, 0, 2, 3, 3, 4, 5, 5, 5): 1, (2, 2, 2, 2, 2, 4, 4, 4): 1, (0, 0, 0, 0, 0, 0, 0): 1, (1, 3, 3, 3, 4, 5): 1, (2, 2, 5, 5): 1, (0, 1, 2, 2, 3, 3): 1, (0, 4, 4, 4, 4, 4): 1, (0, 0, 1, 1, 1, 2, 2, 2, 3, 3, 3, 4, 4, 5): 1, (0, 0, 0, 0, 2, 4, 4, 4): 1, (1, 2, 2, 3): 1, (0, 2, 4, 4, 4, 4, 4): 1, (0, 3, 3, 3): 1, (0, 0, 0, 0, 0, 0): 1, (0, 0, 2, 5): 1, (1, 1, 3, 3, 3, 5, 5, 5, 5): 1, (3, 4, 4, 4, 4): 1, (0, 1, 4, 5): 1, (1, 1, 3, 4, 5): 1, (0, 0, 0, 2, 2, 2, 2, 2, 4): 1, (1, 3, 3, 3, 3, 3, 5, 5): 1, (1, 2, 3, 4): 1, (0, 0, 1, 2, 2): 1, (3, 3, 4, 4): 1, (1, 1, 3, 3, 3, 3, 3, 5): 1, (0, 0, 2, 2, 2, 4, 4, 4, 4): 1, (1, 1, 1, 3, 3, 3, 3, 5): 1, (0, 1, 1, 3, 5): 1, (0, 1, 3, 3, 3): 1, (0, 0, 0, 0, 0, 2, 4, 4): 1, (0, 0, 2, 2, 2, 2, 2, 3, 3, 4): 1, (3, 3, 3, 5, 5, 5, 5, 5, 5): 1, (0, 0, 1, 2, 3): 1, (0, 0, 1, 1, 3): 1, (0, 0, 2, 2, 4, 4, 4, 4, 4): 1, (1, 1, 1, 3, 3, 3, 5): 1, (0, 0, 2, 2, 3, 4): 1, (0, 0, 2, 4, 4, 5, 5): 1, (1, 3, 3, 3, 5, 5, 5, 5, 5): 1, (3, 3, 4, 5, 5, 5): 1, (2, 2, 2, 2, 2, 2, 2, 4): 1, (0, 0, 0, 0, 4, 4, 4): 1, (1, 1, 2, 3, 5, 5): 1, (0, 3, 4, 5): 1, (2, 3, 3, 4, 4): 1, (2, 2, 3, 4, 4, 5): 1, (0, 0, 0, 0, 0, 2, 2): 1, (1, 1, 1, 1, 3, 3, 3, 3): 1, (0, 1, 2, 2, 2, 2): 1, (1, 3, 5, 5, 5, 5, 5, 5): 1, (0, 0, 0, 0, 1): 1, (2, 3, 3, 3, 3, 3, 3, 5, 5): 1, (0, 0, 0, 2, 4, 4, 4, 4, 4): 1, (2, 3, 4, 4): 1, (1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 5, 5): 1, (3, 4, 5, 5): 1, (1, 3, 3, 3, 3, 5, 5, 5, 5): 1, (2, 2, 3, 3, 3, 4, 5, 5): 1, (0, 2, 2, 4, 4, 4, 4, 4, 4, 4): 1, (0, 0, 1, 1, 4): 1, (0, 0, 1, 2, 5): 1, (1, 1, 1, 1, 1, 1, 1): 1, (0, 0, 2, 2, 2, 3, 4, 4, 5): 1, (1, 2, 2, 2, 2, 2, 2, 3): 1, (2, 2, 2, 3, 3): 1, (0, 3, 5): 1, (2, 2, 2, 2, 2, 2, 2): 1, (0, 1, 1, 2, 3, 5): 1, (1, 1, 1, 1, 1, 1, 3, 3): 1, (1, 1, 1, 1, 3, 3, 5, 5): 1, (0, 0, 1, 2, 2, 4): 1, (1, 1, 1, 1, 1, 3, 5): 1, (1, 1, 3, 4): 1, (2, 4, 5, 5): 1, (0, 0, 1, 1, 1, 1): 1, (3, 3, 3, 4, 4, 4, 5): 1, (1, 5, 5, 5, 5, 5): 1, (3, 3, 5, 5, 5, 5, 5, 5, 5): 1, (1, 2, 3, 5): 1, (3, 5, 5, 5, 5, 5, 5): 1, (0, 0, 1, 1, 2, 3): 1, (2, 2, 2, 2, 3, 4, 5): 1, (0, 0, 0, 0, 0, 2, 2, 2, 2, 2): 1, (1, 1, 1, 1, 1, 1, 3, 3, 3, 3, 5): 1, (0, 0, 1, 2, 3, 3, 5): 1, (0, 0, 2, 2, 2, 2, 4, 4, 4, 4): 1, (2, 2, 3, 4, 5, 5, 5): 1, (0, 0, 0, 1, 2, 3): 1, (0, 1, 1, 1, 1): 1, (1, 2, 4, 5): 1, (1, 1, 1, 1, 1, 1, 3, 3, 3): 1, (1, 1, 1, 1, 1, 1, 1, 3): 1, (0, 0, 2, 2, 2, 2, 4, 4, 4): 1, (3, 3, 3, 3, 5, 5, 5, 5, 5): 1, (2, 4, 4, 4, 5, 5): 1, (1, 1, 1, 5, 5, 5, 5): 1, (0, 0, 1, 1, 1): 1, (0, 0, 0, 1, 1, 1): 1, (0, 1, 1, 3, 3, 4, 5): 1, (0, 0, 0, 0, 2, 2, 2, 4): 1, (4, 4, 4, 4, 4, 4, 5): 1, (0, 0, 2, 4, 4, 4, 4): 1, (0, 1, 1, 1, 2): 1, (0, 2, 2, 2, 2, 4, 4): 1, (0, 3, 4, 4): 1, (0, 2, 2, 2, 3): 1, (2, 2, 2, 2, 2, 4, 4): 1, (1, 1, 1, 1, 2, 4, 5): 1, (0, 0, 0, 0, 0, 0, 2, 2, 2, 4): 1, (0, 0, 1, 1, 2): 1, (2, 2, 2, 2, 2, 5): 1, (1, 1, 1, 5, 5, 5, 5, 5): 1, (0, 0, 0, 2, 2, 2, 4, 4): 1, (0, 0, 0, 0, 2, 2, 2, 4, 4): 1}\n",
    "sample = 'C1705'\n",
    "read_groups = ['H8VFV.1', 'H8VFV.1.1', 'H8VJG.1', 'H8VJG.1.3', 'H8VJG.2', 'H8VJG.2.5']\n",
    "libraries = ['Pond-342622', 'Pond-342631', 'Pond-342622', 'Pond-342631', 'Pond-342622', 'Pond-342631']\n",
    "\n",
    "# john's stuff\n",
    "n_groups = len(read_groups)\n",
    "rg_sizes = group_sizes(table, n_groups)\n",
    "lib_nums = library_nums(libraries)\n",
    "n_libraries = np.max(lib_nums)\n",
    "lib_matrix = library_matrix(lib_nums, n_groups)\n",
    "lib_color = library_colors(lib_nums)\n",
    "ol_affinity = overlap_affinity(table, n_groups)\n",
    "mult_matrix = multiplicity_matrix(table, n_groups)\n",
    "mult_matrix2 = normalize_rows_by_vector(mult_matrix, rg_sizes)\n",
    "el2_affinity = L2_affinity(table, n_groups)\n",
    "angle_matrix = np.arccos(el2_affinity)\n",
    "ap_affinity = all_pairs_affinity(table, n_groups)\n",
    "ap_affinity2 = all_pairs_affinity2(table, n_groups, rg_sizes)\n",
    "ep_affinity = exact_pairs_affinity(table, n_groups)\n",
    "ep_affinity2 = exact_pairs_affinity2(table, n_groups, rg_sizes)\n",
    "evals1, evecs1 = eigen(el2_affinity)\n",
    "evals2, evecs2 = eigen(ap_affinity)\n",
    "dd_matrix1 = diffusion_distances(evals1,evecs1)\n",
    "dd_matrix2 = diffusion_distances(evals2,evecs2)\n",
    "\n",
    "print \"ap_affinity\"\n",
    "print ap_affinity\n",
    "print \"sums\"\n",
    "row_sums = ap_affinity.sum(axis=1)\n",
    "print row_sums\n",
    "print \"row_sums[:, np.newaxis]\"\n",
    "denom = row_sums[:, np.newaxis]\n",
    "print denom\n",
    "print \"num/denom\"\n",
    "print ap_affinity / denom\n",
    "print \"function\"\n",
    "print normalize_to_Markov(ap_affinity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "#%time\n",
    "\n",
    "import json\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "from scipy.misc import comb\n",
    "from scipy.special import binom\n",
    "import scipy.stats as ss\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import LogNorm\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from collections import Counter\n",
    "from __future__ import division\n",
    "\n",
    "def load_table(sample):\n",
    "    f = open(sample + '.table.txt', 'r')\n",
    "    read_groups = eval(f.readline())\n",
    "    libraries = eval(f.readline())\n",
    "    n_reads = eval(f.readline())\n",
    "    n_reads_removed = eval(f.readline())\n",
    "    table = eval(f.readline())\n",
    "    f.close()\n",
    "    return read_groups, libraries, n_reads, n_reads_removed, table\n",
    "\n",
    "def group_sizes(table, n_groups):\n",
    "    '''Returns vector v where v[i] is count of reads in group i.'''\n",
    "    rg_sizes = np.zeros(n_groups, dtype=int)\n",
    "    for item in table.items():\n",
    "        for i in item[0]:\n",
    "            rg_sizes[i] += item[1]\n",
    "    return rg_sizes\n",
    "\n",
    "def remove_empty_groups(read_groups, libraries, table):\n",
    "    n_groups = len(read_groups)\n",
    "    rg_sizes = group_sizes(table, n_groups)\n",
    "    if np.prod(rg_sizes != 0):\n",
    "        return read_groups, libraries, table\n",
    "    else:\n",
    "        groups = [read_groups[i] for i in range(n_groups) if rg_sizes[i] != 0]\n",
    "        libs = [libraries[i] for i in range(n_groups) if rg_sizes[i] != 0]\n",
    "        new_num_of_old_num = {}\n",
    "        current_num = 0\n",
    "        for i in range(n_groups):\n",
    "            new_num_of_old_num[i] = current_num\n",
    "            if rg_sizes[i] != 0:\n",
    "                current_num += 1\n",
    "        new_table = Counter()\n",
    "        for item in table.items():\n",
    "            new_key = tuple(map(lambda x : new_num_of_old_num[x], list(item[0])))\n",
    "            new_table.update({new_key : item[1]})\n",
    "        return groups, libs, new_table\n",
    "    \n",
    "def library_nums(libraries):\n",
    "    n_groups = len(libraries)\n",
    "    num_of_library = {}\n",
    "    current_num = 0\n",
    "    for i in xrange(n_groups):\n",
    "        if libraries[i] not in num_of_library.keys(): #change to set_default\n",
    "            num_of_library[libraries[i]] = current_num\n",
    "            current_num += 1\n",
    "    return np.array([num_of_library[libraries[i]] for i in xrange(n_groups)])\n",
    "\n",
    "def library_colors(lib_nums):\n",
    "    #lib_color = plt.cm.Set1(lib_nums / (n_libraries + 1))\n",
    "    color_of_num = {0 : 'r', 1 : 'b', 2 : 'g', 3 : 'k', 4 : 'y', 5 : 'm', 6 : 'c'}\n",
    "    return [color_of_num[lib_num % 5] for lib_num in lib_nums]\n",
    "\n",
    "def library_matrix(lib_nums, n_groups):\n",
    "    lib_matrix = np.zeros((n_groups,n_groups), dtype=bool)\n",
    "    for i in xrange(n_groups):\n",
    "        for j in xrange(n_groups):\n",
    "            lib_matrix[i,j] = (lib_nums[i] == lib_nums[j])\n",
    "    return lib_matrix\n",
    "\n",
    "# jaccard similarity. union/intersection. might not be robust to diff conditions. no a priori expectation\n",
    "def overlaps(table, n_groups):\n",
    "    '''Returns matrix where M[i][j] is count of read types in both groups i\n",
    "       and group j (symmetrized)'''\n",
    "    overlap_matrix = np.zeros((n_groups, n_groups))\n",
    "    for item in table.items():\n",
    "        groups = list(set(item[0]))\n",
    "        l = len(groups)\n",
    "        for i in xrange(0,l):\n",
    "            for j in xrange(i,l):\n",
    "                overlap_matrix[groups[i],groups[j]] += item[1]\n",
    "    return (overlap_matrix + overlap_matrix.T) / 2\n",
    "\n",
    "def inner_product(table, n_groups):\n",
    "    '''Returns matrix X^t * X where X[i,j] is count of reads of type i in group j.\n",
    "       Agrees with all_pairs off the diagonal.'''\n",
    "    ip_matrix = np.zeros((n_groups,n_groups))\n",
    "    for item in table.items():\n",
    "        l = len(item[0])\n",
    "        count_vector = np.zeros(n_groups)\n",
    "        for i in xrange(l):\n",
    "            count_vector[item[0][i]] += 1\n",
    "        ip_matrix += np.outer(count_vector, count_vector) * item[1]\n",
    "    return ip_matrix\n",
    "\n",
    "\n",
    "# ABB would be 3 pairs- AB, AB, BB\n",
    "# Retain signal from non-exact pairs. didn't do this as the only metric bc seeing a lot of on-flowcell pad-hopping duplicates, showing up as large duplicate sets, which would dominate here\n",
    "# We only want biological duplicates, and we have been better at marking these. The work yossi and david benj are doing. What's going on from david roazen.\n",
    "# That wasn't ready yet, so he did an exact pairs approach as well.\n",
    "# This one is probably best if you are careful to look at only biological duplicates\n",
    "def all_pairs(table, n_groups):\n",
    "    '''Returns matrix where M[i,j] is count of matching pairs of distinct reads\n",
    "       from groups i and j (symmetrized).'''\n",
    "    ap_matrix = np.zeros((n_groups,n_groups))\n",
    "    for item in table.items():\n",
    "        l = len(item[0])\n",
    "        for i in xrange(l-1):\n",
    "            for j in xrange(i+1,l):\n",
    "                ap_matrix[item[0][i],item[0][j]] += item[1]\n",
    "    return (ap_matrix + np.tril(ap_matrix.T))/2\n",
    "\n",
    "def exact_tuples(table, n_groups, k):\n",
    "    '''Returns array where A[i_1,...i_k] is count of read types that occur\n",
    "       exactly in the groups i_1,...,i_k ascending with repeats.'''\n",
    "    et_array = np.zeros(k*(n_groups,))\n",
    "    for item in table.items():\n",
    "        if len(item[0])==k:\n",
    "            et_array[item[0]] = item[1]\n",
    "    return et_array\n",
    "\n",
    "def exact_pairs(table, n_groups):\n",
    "    '''Returns matrix where M[i,j] is count of read types that occur exactly twice,\n",
    "       once in group i and once in group j (symmetrized).'''\n",
    "    ep_matrix = exact_tuples(table, n_groups, 2)\n",
    "    return (ep_matrix + np.tril(ep_matrix.T))/2\n",
    "\n",
    "def normalize(array):\n",
    "    return array/np.sum(array)\n",
    "\n",
    "# normalize such that diagonals are 1 (so 1 is max self-similarity). off-diag things scaled proportionally\n",
    "def normalize_by_diagonal(matrix):\n",
    "    diag = np.diagonal(matrix)\n",
    "    return matrix / np.sqrt(np.outer(diag, diag))\n",
    "\n",
    "# take the outer product of [pq] with itself\n",
    "# ie [[p^2, pq], [pq, q^2]]\n",
    "# so divide matrix by [[p, rad(pq)], [rad(pq), q]]\n",
    "# so each cell is divided by the total number of elements in it's thing.\n",
    "# most similar to the underlying model\n",
    "def normalize_by_group_size(matrix, group_sizes):\n",
    "    return matrix / np.sqrt(np.outer(group_sizes, group_sizes))\n",
    "\n",
    "def normalize_rows_by_vector(matrix, vector):\n",
    "    return matrix / vector[:, np.newaxis]\n",
    "\n",
    "def overlap_affinity(table, n_groups):\n",
    "    ol_matrix = overlaps(table, n_groups)\n",
    "    ol_affinity = np.zeros((n_groups, n_groups))\n",
    "    for i in xrange(n_groups):\n",
    "        ol_affinity[i,i] = .5\n",
    "        for j in xrange(i+1,n_groups):\n",
    "            ol_affinity[i,j] = 2 * ol_matrix[i,j] / \\\n",
    "                               (ol_matrix[i,i] + ol_matrix[j,j] - 2 * ol_matrix[i,j])\n",
    "    return ol_affinity + ol_affinity.T\n",
    "\n",
    "def exact_pairs_affinity(table, n_groups):\n",
    "    return normalize_by_diagonal(exact_pairs(table, n_groups))\n",
    "\n",
    "def all_pairs_affinity(table, n_groups):\n",
    "    return normalize_by_diagonal(all_pairs(table, n_groups))\n",
    "\n",
    "# Distance in euclidean space between 2 vectrs. each RG is a vector in a space whose dimension is the number of non-zero entries in the union of observed inserts\n",
    "# so, what's teh cosine fo the angle between these 2 vectors\n",
    "# naturally, the diagonal elements will be 1\n",
    "# cosine of angle = (A dot B) / (length A)(length B)\n",
    "\n",
    "# BUT our data isn't in the form of these vectors. So we count the AB pairs.\n",
    "# Recording each time he sees some combination of 2 numbers.\n",
    "\n",
    "# suffers the same issue as jaccard- what is your expectation. this is why all pairs and exact pairs only viable.\n",
    "def L2_affinity(table, n_groups):\n",
    "    return normalize_by_diagonal(inner_product(table, n_groups))\n",
    "\n",
    "def exact_pairs_affinity2(table, n_groups, rg_sizes):\n",
    "    return normalize(normalize_by_group_size(exact_pairs(table, n_groups),rg_sizes))\n",
    "\n",
    "def all_pairs_affinity2(table, n_groups, rg_sizes):\n",
    "    return normalize(normalize_by_group_size(all_pairs(table, n_groups),rg_sizes))\n",
    "\n",
    "def zero_diag(matrix):\n",
    "    new_matrix = matrix.copy()\n",
    "    for i in xrange(matrix.shape[0]):\n",
    "        new_matrix[i,i] = 0\n",
    "    return new_matrix\n",
    "\n",
    "def multiplicity_matrix(table, n_groups):\n",
    "    '''Returns M with M_ij count of j-tuples in group i'''\n",
    "    max_mult =  max(map(len,table.keys()))\n",
    "    mult_matrix = np.zeros((n_groups, max_mult + 1), dtype=int)\n",
    "    for i in xrange(n_groups):\n",
    "        mult_vector = multiplicity_vector(subtable(table,i))\n",
    "        for j in xrange(len(mult_vector)):\n",
    "            mult_matrix[i,j] = mult_vector[j]\n",
    "    return mult_matrix\n",
    "\n",
    "def multiplicity_vector(table):\n",
    "    '''Returns v with v_j count of j-tuples in table'''\n",
    "    max_mult =  max(map(len,table.keys()))\n",
    "    mult_vector = np.zeros(max_mult + 1, dtype=int)\n",
    "    for item in table.items():\n",
    "        mult_vector[len(item[0])] += item[1]   \n",
    "    return mult_vector\n",
    "\n",
    "def subtable(table, i):\n",
    "    '''Returns subtable for group i'''\n",
    "    group_table = Counter()\n",
    "    for item in table.items():\n",
    "        mult = item[0].count(i)\n",
    "        if mult > 0:\n",
    "            group_table.update({(i,)*mult : item[1]})\n",
    "    return group_table\n",
    "\n",
    "def plot_matrix_rows(matrix, title = 'Matrix rows'):\n",
    "    max_mult = np.sum(np.sum(matrix,axis=0) > 0) - 1\n",
    "    for i in xrange(n_groups):\n",
    "        plt.semilogy(range(1, max_mult + 3), matrix[i,1:max_mult + 3],\n",
    "                 label=i, color = plt.cm.Set1(i/n_groups))\n",
    "    #plt.yscale('log')\n",
    "    plt.ylim(np.min(matrix), 10 * np.max(matrix))\n",
    "    plt.title(title)\n",
    "    plt.legend(title='RG')\n",
    "    plt.show() #change ticks to integers only\n",
    "\n",
    "def plot_matrix(matrix, title='Matrix', vmax=None):\n",
    "    n, m = matrix.shape\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "    plt.pcolor(matrix, edgecolor='k', cmap = plt.cm.Blues, vmin=0, vmax=vmax)\n",
    "    plt.colorbar()\n",
    "    ax.set_xticks(np.arange(n)+0.5)\n",
    "    ax.set_yticks(np.arange(m)+0.5)\n",
    "    ax.set_xticklabels(np.arange(n))\n",
    "    ax.set_yticklabels(np.arange(m))\n",
    "    ax.set_title(title)\n",
    "    ax.invert_yaxis()\n",
    "    plt.show()\n",
    "\n",
    "def normalize_to_Markov(matrix):\n",
    "    row_sums = matrix.sum(axis=1)\n",
    "    return matrix / row_sums[:, np.newaxis]\n",
    "    \n",
    "def eigen(affinity):\n",
    "    #change to computer for symmetrix matrix and convert?\n",
    "    #is absolute value necessary? correct? won't fractoinal powers cause trouble?\n",
    "    evals, evecs = np.linalg.eig(normalize_to_Markov(affinity))\n",
    "    order = np.argsort(np.abs(evals))[::-1]\n",
    "    return evals[order], evecs[:,order]\n",
    "\n",
    "def diffusion_distances(evals, evecs, t = None):\n",
    "    if not t:\n",
    "        t = 1 / (1-evals[1])\n",
    "    n_groups = len(evals)\n",
    "    scaled_evecs = evecs[:,1:] * evals[1:]**t  #check that this works as expected\n",
    "    dd_matrix = np.zeros((n_groups,n_groups))\n",
    "    for i in xrange(n_groups):\n",
    "        dd_matrix[i,i]=0\n",
    "        for j in xrange(i+1, n_groups):\n",
    "            difference = scaled_evecs[i,:] - scaled_evecs[j,:]\n",
    "            dd_matrix[i,j] = np.sqrt(np.dot(difference,difference))\n",
    "    return dd_matrix + dd_matrix.T\n",
    "\n",
    "def plot_diffusion(evals, evecs, t=None, bound=None, title='Diffusion', color=None):\n",
    "    if not t:\n",
    "        t = 1 / (1-evals[1])\n",
    "    x = evecs[:,1]*(evals[1]**t)\n",
    "    y = evecs[:,2]*(evals[2]**t)\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "    lib_nums = library_nums(libraries)\n",
    "    ax.scatter(x, y, color=color)\n",
    "    ax.set_title(title)\n",
    "    if bound:\n",
    "        ax.set_xlim(-bound,bound)\n",
    "        ax.set_ylim(-bound,bound)\n",
    "    plt.show()\n",
    "\n",
    "def plot_diffusion_3d(evals, evecs, t=None, bound=None, title='Diffusion', color=None):\n",
    "    if not t:\n",
    "        t = 1 / (1-evals[1])\n",
    "    x = evecs[:,1]*(evals[1]**t)\n",
    "    y = evecs[:,2]*(evals[2]**t)\n",
    "    z = evecs[:,3]*(evals[3]**t)\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111,projection=\"3d\")\n",
    "    ax.scatter3D(x, y, z, color = color)\n",
    "    ax.set_title(title)\n",
    "    if bound:\n",
    "        ax.set_xlim3d(-bound,bound)\n",
    "        ax.set_ylim3d(-bound,bound)\n",
    "        ax.set_zlim3d(-bound,bound)\n",
    "    plt.show()\n",
    "\n",
    "def scatter_affinities(affinities, lib_matrices, pair_colors, log_scale = False, title='Scatter'):   \n",
    "    fig = plt.figure(figsize=(10,8))\n",
    "    xs = np.arange(len(pair_colors))\n",
    "    plt.scatter(xs, affinities, s=2, color = pair_colors)\n",
    "    plt.title(title)\n",
    "    plt.ylim(1e-6,1)\n",
    "    if log_scale == True:\n",
    "        plt.yscale('log')\n",
    "    for i in xs:\n",
    "        if lib_matrices[i] == 3:\n",
    "            plt.axvline(x=i,ls='-',alpha = .5,c='g',linewidth=1,)\n",
    "    plt.show()\n",
    "    \n",
    "def plot_graph(matrix, threshold, color=None, complement = False):\n",
    "    print 'Threshold =', threshold #include this in title\n",
    "    n_groups = matrix.shape[0]\n",
    "    labels = dict(zip(range(n_groups),range(n_groups)))\n",
    "    if complement:\n",
    "        G = nx.Graph(matrix < threshold)\n",
    "    else:\n",
    "        G = nx.Graph(matrix >= threshold)\n",
    "    pos=nx.spring_layout(G)\n",
    "    nx.draw_networkx_nodes(G,pos,node_color=color)\n",
    "    nx.draw_networkx_edges(G,pos)\n",
    "    nx.draw_networkx_labels(G,pos,labels=labels,font_color='w',font_size=16)\n",
    "    plt.show()\n",
    "\n",
    "# read_groups = ['bloop']\n",
    "# a = ['NexPond-544501'] * 7\n",
    "# b = ['NexPond-544405'] * 8\n",
    "# libraries = a + b\n",
    "# print libraries\n",
    "\n",
    "def read_metadata(meta_file):\n",
    "    with open(meta_file, 'r') as f:\n",
    "        my_json = json.loads(f.read())\n",
    "    return {json.loads(key): value for (key, value) in my_json.iteritems()}\n",
    "\n",
    "def read_table(table_file):\n",
    "    with open(table_file, 'r') as f:\n",
    "        # This will initially read the keys in the k:v pairs as just strings\n",
    "        my_json = json.loads(f.read())\n",
    "    # Convert keys string->list; but cannot hash on a list, so conver to a tuple for use in the map\n",
    "    return {tuple(json.loads(key)): value for (key, value) in my_json.iteritems()}\n",
    "\n",
    "def is_greater_than(x, threshold):\n",
    "    return 1 if x > threshold else 0\n",
    "\n",
    "meta = read_metadata('test_2_libraries.tabledata.json.read_groups.json')\n",
    "table = read_table('test2libs.tabledata.json')  \n",
    "\n",
    "# meta = read_metadata('test_10_libraries.read_groups.json')\n",
    "# table = read_table('test_10_libraries.table.json')  \n",
    "\n",
    "groups = []\n",
    "libraries = []\n",
    "for key in meta.keys():\n",
    "    libraries.append(meta[key]['mAttributes']['LB'])\n",
    "    groups.append(meta[key]['mReadGroupId'])\n",
    "\n",
    "n_groups = len(groups)\n",
    "\n",
    "print \"floop\"\n",
    "\n",
    "arrays = [np.array(groups), np.array(libraries)]\n",
    "\n",
    "print \"nloop\"\n",
    "\n",
    "ap_affinity = all_pairs_affinity(table, n_groups)\n",
    "\n",
    "print \"bloop\"\n",
    "\n",
    "df = pd.DataFrame(zero_diag(ap_affinity), index=arrays, columns=arrays)\n",
    "\n",
    "print \"gloop\"\n",
    "\n",
    "df = df.sort_index(level=1)\n",
    "df = df.sort_index(level=1, axis=1)\n",
    "\n",
    "# print df\n",
    "\n",
    "# print df.index\n",
    "# print df.columns\n",
    "\n",
    "print df.iat[0,0]\n",
    "\n",
    "is_same = np.vectorize(is_greater_than)\n",
    "# result = is_same(ap_affinity, 0.5)\n",
    "result = is_same(df, 0.5)\n",
    "\n",
    "# print df.values\n",
    "# print result\n",
    "\n",
    "truth = np.zeros((n_groups,n_groups))\n",
    "for i in xrange(n_groups):\n",
    "    for j in xrange(n_groups):\n",
    "        if libraries[i] == libraries[j] and i !=j:\n",
    "            truth[i,j] = 1\n",
    "            \n",
    "# print truth\n",
    "\n",
    "# print truth[truth > 0]\n",
    "\n",
    "# truthy = pd.DataFrame(truth, index=arrays, columns=arrays)\n",
    "true_sames = result[truth > 0]\n",
    "n_same_given_true_same = true_sames.sum() \n",
    "p_same_given_true_same = n_same_given_true_same / len(true_sames)\n",
    "print \"p(same-library | truly same-library) = {0:.2f}\".format(round(p_same_given_true_same))\n",
    "\n",
    "true_diffs = result[truth == 0]\n",
    "n_diff_given_true_diff = len(true_diffs) - true_diffs.sum()\n",
    "p_diff_given_true_diff = n_diff_given_true_diff / len(true_diffs)\n",
    "print \"p(different-library | truly different-library) = {0:.2f}\".format(round(p_diff_given_true_diff))\n",
    "\n",
    "rand_index = (n_same_given_true_same + n_diff_given_true_diff) / (n_groups * n_groups)\n",
    "print \"Rand index = {0:.2f}\".format(round(rand_index,2))\n",
    "\n",
    "vals_of_sames = df.values[truth>0]\n",
    "vals_of_diffs = df.values[truth==0]\n",
    "print vals_of_sames\n",
    "print vals_of_diffs\n",
    "\n",
    "my_bins=np.arange(-0.01,1,.01)\n",
    "\n",
    "plt.hist(vals_of_sames, bins=my_bins, alpha=0.5, label='Same-library')\n",
    "plt.hist(vals_of_diffs, bins=my_bins, alpha=0.5, label='Different-library')\n",
    "plt.legend(loc='upper right')\n",
    "# plt.hist(ap_affinity, bins=np.arange(,1,.001))\n",
    "plt.show()\n",
    "\n",
    "# print np.matrix([[result[i,j] for i in xrange(n_groups)] for j in xrange(n_groups)])\n",
    "\n",
    "\n",
    "# print \"floop\"\n",
    "\n",
    "# failed = False\n",
    "# for i in xrange(n_groups):\n",
    "#     for j in xrange(i, n_groups):\n",
    "#         libi = libraries[i]\n",
    "#         libj = libraries[j]\n",
    "#         test = result[i][j]\n",
    "#         truth = 1 if libi==libj else 0\n",
    "# #         print i,j, test, truth\n",
    "        \n",
    "#         if test!=truth: failed = True\n",
    "            \n",
    "# print failed\n",
    "        \n",
    "\n",
    "# plot_matrix(zero_diag(ap_affinity), title='All pairs affinity')\n",
    "# plot_matrix(df, title='All pairs affinity')\n",
    "\n",
    "print \"FLOMP\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "thing = np.array([1,0,-1])\n",
    "np.abs(thing).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
