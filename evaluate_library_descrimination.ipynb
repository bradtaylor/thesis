{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "from scipy.misc import comb\n",
    "import scipy.stats as ss\n",
    "from scipy.stats import beta, chisqprob\n",
    "from scipy.special import gamma as gammaf # This is dumb but better for the moment than fixing code against jon's\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import LogNorm\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from collections import Counter\n",
    "from __future__ import division\n",
    "\n",
    "import json\n",
    "from sys import maxint\n",
    "from scipy.special import binom\n",
    "from IPython.display import display, HTML\n",
    "from sklearn.cross_validation import KFold\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Inline all plots to cell outputs\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Distance functions and utility functions by Jon Bloom\n",
    "\n",
    "def load_table(sample):\n",
    "    f = open(sample + '.table.txt', 'r')\n",
    "    read_groups = eval(f.readline())\n",
    "    libraries = eval(f.readline())\n",
    "    n_reads = eval(f.readline())\n",
    "    n_reads_removed = eval(f.readline())\n",
    "    table = eval(f.readline())\n",
    "    f.close()\n",
    "    return read_groups, libraries, n_reads, n_reads_removed, table\n",
    "\n",
    "def group_sizes(table, n_groups):\n",
    "    '''Returns vector v where v[i] is count of reads in group i.'''\n",
    "    rg_sizes = np.zeros(n_groups, dtype=int)\n",
    "    for item in table.items():\n",
    "        for i in item[0]:\n",
    "            rg_sizes[i] += item[1]\n",
    "    return rg_sizes\n",
    "\n",
    "def remove_empty_groups(read_groups, libraries, table):\n",
    "    n_groups = len(read_groups)\n",
    "    rg_sizes = group_sizes(table, n_groups)\n",
    "    if np.prod(rg_sizes != 0):\n",
    "        return read_groups, libraries, table\n",
    "    else:\n",
    "        groups = [read_groups[i] for i in range(n_groups) if rg_sizes[i] != 0]\n",
    "        libs = [libraries[i] for i in range(n_groups) if rg_sizes[i] != 0]\n",
    "        new_num_of_old_num = {}\n",
    "        current_num = 0\n",
    "        for i in range(n_groups):\n",
    "            new_num_of_old_num[i] = current_num\n",
    "            if rg_sizes[i] != 0:\n",
    "                current_num += 1\n",
    "        new_table = Counter()\n",
    "        for item in table.items():\n",
    "            new_key = tuple(map(lambda x : new_num_of_old_num[x], list(item[0])))\n",
    "            new_table.update({new_key : item[1]})\n",
    "        return groups, libs, new_table\n",
    "    \n",
    "def library_nums(libraries):\n",
    "    n_groups = len(libraries)\n",
    "    num_of_library = {}\n",
    "    current_num = 0\n",
    "    for i in xrange(n_groups):\n",
    "        if libraries[i] not in num_of_library.keys(): #change to set_default\n",
    "            num_of_library[libraries[i]] = current_num\n",
    "            current_num += 1\n",
    "    return np.array([num_of_library[libraries[i]] for i in xrange(n_groups)])\n",
    "\n",
    "def library_colors(lib_nums):\n",
    "    #lib_color = plt.cm.Set1(lib_nums / (n_libraries + 1))\n",
    "    color_of_num = {0 : 'r', 1 : 'b', 2 : 'g', 3 : 'k', 4 : 'y', 5 : 'm', 6 : 'c'}\n",
    "    return [color_of_num[lib_num % 5] for lib_num in lib_nums]\n",
    "\n",
    "def library_matrix(lib_nums, n_groups):\n",
    "    lib_matrix = np.zeros((n_groups,n_groups), dtype=bool)\n",
    "    for i in xrange(n_groups):\n",
    "        for j in xrange(n_groups):\n",
    "            lib_matrix[i,j] = (lib_nums[i] == lib_nums[j])\n",
    "    return lib_matrix\n",
    "\n",
    "# jaccard similarity. union/intersection. might not be robust to diff conditions. no a priori expectation\n",
    "def overlaps(table, n_groups):\n",
    "    '''Returns matrix where M[i][j] is count of read types in both groups i\n",
    "       and group j (symmetrized)'''\n",
    "    overlap_matrix = np.zeros((n_groups, n_groups))\n",
    "    for item in table.items():\n",
    "        groups = list(set(item[0]))\n",
    "        l = len(groups)\n",
    "        for i in xrange(0,l):\n",
    "            for j in xrange(i,l):\n",
    "                overlap_matrix[groups[i],groups[j]] += item[1]\n",
    "    return (overlap_matrix + overlap_matrix.T) / 2\n",
    "\n",
    "def inner_product(table, n_groups):\n",
    "    '''Returns matrix X^t * X where X[i,j] is count of reads of type i in group j.\n",
    "       Agrees with all_pairs off the diagonal.'''\n",
    "    ip_matrix = np.zeros((n_groups,n_groups))\n",
    "    for item in table.items():\n",
    "        l = len(item[0])\n",
    "        count_vector = np.zeros(n_groups)\n",
    "        for i in xrange(l):\n",
    "            count_vector[item[0][i]] += 1\n",
    "        ip_matrix += np.outer(count_vector, count_vector) * item[1]\n",
    "    return ip_matrix\n",
    "\n",
    "\n",
    "# ABB would be 3 pairs- AB, AB, BB\n",
    "# Retain signal from non-exact pairs. didn't do this as the only metric bc seeing a lot of on-flowcell pad-hopping duplicates, showing up as large duplicate sets, which would dominate here\n",
    "# We only want biological duplicates, and we have been better at marking these. The work yossi and david benj are doing. What's going on from david roazen.\n",
    "# That wasn't ready yet, so he did an exact pairs approach as well.\n",
    "# This one is probably best if you are careful to look at only biological duplicates\n",
    "def all_pairs(table, n_groups):\n",
    "    '''Returns matrix where M[i,j] is count of matching pairs of distinct reads\n",
    "       from groups i and j (symmetrized).'''\n",
    "    ap_matrix = np.zeros((n_groups,n_groups))\n",
    "    for item in table.items():\n",
    "        l = len(item[0])\n",
    "        for i in xrange(l-1):\n",
    "            for j in xrange(i+1,l):\n",
    "                ap_matrix[item[0][i],item[0][j]] += item[1]\n",
    "    return (ap_matrix + np.tril(ap_matrix.T))/2\n",
    "\n",
    "def exact_tuples(table, n_groups, k):\n",
    "    '''Returns array where A[i_1,...i_k] is count of read types that occur\n",
    "       exactly in the groups i_1,...,i_k ascending with repeats.'''\n",
    "    et_array = np.zeros(k*(n_groups,))\n",
    "    for item in table.items():\n",
    "        if len(item[0])==k:\n",
    "            et_array[item[0]] = item[1]\n",
    "    return et_array\n",
    "\n",
    "def exact_pairs(table, n_groups):\n",
    "    '''Returns matrix where M[i,j] is count of read types that occur exactly twice,\n",
    "       once in group i and once in group j (symmetrized).'''\n",
    "    ep_matrix = exact_tuples(table, n_groups, 2)\n",
    "    return (ep_matrix + np.tril(ep_matrix.T))/2\n",
    "\n",
    "def normalize(array):\n",
    "    return array/np.sum(array)\n",
    "\n",
    "# normalize such that diagonals are 1 (so 1 is max self-similarity). off-diag things scaled proportionally\n",
    "def normalize_by_diagonal(matrix):\n",
    "    diag = np.diagonal(matrix)\n",
    "    return matrix / np.sqrt(np.outer(diag, diag))\n",
    "\n",
    "# take the outer product of [pq] with itself\n",
    "# ie [[p^2, pq], [pq, q^2]]\n",
    "# so divide matrix by [[p, rad(pq)], [rad(pq), q]]\n",
    "# so each cell is divided by the total number of elements in it's thing.\n",
    "# most similar to the underlying model\n",
    "def normalize_by_group_size(matrix, group_sizes):\n",
    "    return matrix / np.sqrt(np.outer(group_sizes, group_sizes))\n",
    "\n",
    "def normalize_rows_by_vector(matrix, vector):\n",
    "    return matrix / vector[:, np.newaxis]\n",
    "\n",
    "def overlap_affinity(table, n_groups):\n",
    "    ol_matrix = overlaps(table, n_groups)\n",
    "    ol_affinity = np.zeros((n_groups, n_groups))\n",
    "    for i in xrange(n_groups):\n",
    "        ol_affinity[i,i] = .5\n",
    "        for j in xrange(i+1,n_groups):\n",
    "            ol_affinity[i,j] = 2 * ol_matrix[i,j] / \\\n",
    "                               (ol_matrix[i,i] + ol_matrix[j,j] - 2 * ol_matrix[i,j])\n",
    "    return ol_affinity + ol_affinity.T\n",
    "\n",
    "def exact_pairs_affinity(table, n_groups):\n",
    "    return normalize_by_diagonal(exact_pairs(table, n_groups))\n",
    "\n",
    "def all_pairs_affinity(table, n_groups):\n",
    "    return normalize_by_diagonal(all_pairs(table, n_groups))\n",
    "\n",
    "# Distance in euclidean space between 2 vectrs. each RG is a vector in a space whose dimension is the number of non-zero entries in the union of observed inserts\n",
    "# so, what's teh cosine fo the angle between these 2 vectors\n",
    "# naturally, the diagonal elements will be 1\n",
    "# cosine of angle = (A dot B) / (length A)(length B)\n",
    "\n",
    "# BUT our data isn't in the form of these vectors. So we count the AB pairs.\n",
    "# Recording each time he sees some combination of 2 numbers.\n",
    "\n",
    "# suffers the same issue as jaccard- what is your expectation. this is why all pairs and exact pairs only viable.\n",
    "def L2_affinity(table, n_groups):\n",
    "    return normalize_by_diagonal(inner_product(table, n_groups))\n",
    "\n",
    "def exact_pairs_affinity2(table, n_groups, rg_sizes):\n",
    "    return normalize(normalize_by_group_size(exact_pairs(table, n_groups),rg_sizes))\n",
    "\n",
    "def all_pairs_affinity2(table, n_groups, rg_sizes):\n",
    "    return normalize(normalize_by_group_size(all_pairs(table, n_groups),rg_sizes))\n",
    "\n",
    "def zero_diag(matrix):\n",
    "    new_matrix = matrix.copy()\n",
    "    for i in xrange(matrix.shape[0]):\n",
    "        new_matrix[i,i] = 0\n",
    "    return new_matrix\n",
    "\n",
    "def multiplicity_matrix(table, n_groups):\n",
    "    '''Returns M with M_ij count of j-tuples in group i'''\n",
    "    max_mult =  max(map(len,table.keys()))\n",
    "    mult_matrix = np.zeros((n_groups, max_mult + 1), dtype=int)\n",
    "    for i in xrange(n_groups):\n",
    "        mult_vector = multiplicity_vector(subtable(table,i))\n",
    "        for j in xrange(len(mult_vector)):\n",
    "            mult_matrix[i,j] = mult_vector[j]\n",
    "    return mult_matrix\n",
    "\n",
    "def multiplicity_vector(table):\n",
    "    '''Returns v with v_j count of j-tuples in table'''\n",
    "    max_mult =  max(map(len,table.keys()))\n",
    "    mult_vector = np.zeros(max_mult + 1, dtype=int)\n",
    "    for item in table.items():\n",
    "        mult_vector[len(item[0])] += item[1]   \n",
    "    return mult_vector\n",
    "\n",
    "def subtable(table, i):\n",
    "    '''Returns subtable for group i'''\n",
    "    group_table = Counter()\n",
    "    for item in table.items():\n",
    "        mult = item[0].count(i)\n",
    "        if mult > 0:\n",
    "            group_table.update({(i,)*mult : item[1]})\n",
    "    return group_table\n",
    "\n",
    "def plot_matrix_rows(matrix, title = 'Matrix rows'):\n",
    "    max_mult = np.sum(np.sum(matrix,axis=0) > 0) - 1\n",
    "    for i in xrange(n_groups):\n",
    "        plt.semilogy(range(1, max_mult + 3), matrix[i,1:max_mult + 3],\n",
    "                 label=i, color = plt.cm.Set1(i/n_groups))\n",
    "    #plt.yscale('log')\n",
    "    plt.ylim(np.min(matrix), 10 * np.max(matrix))\n",
    "    plt.title(title)\n",
    "    plt.legend(title='RG')\n",
    "    plt.show() #change ticks to integers only\n",
    "\n",
    "def plot_matrix(matrix, title='Matrix', vmax=None):\n",
    "    n, m = matrix.shape\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "    plt.pcolor(matrix, edgecolor='k', cmap = plt.cm.Blues, vmin=0, vmax=vmax)\n",
    "    plt.colorbar()\n",
    "    ax.set_xticks(np.arange(n)+0.5)\n",
    "    ax.set_yticks(np.arange(m)+0.5)\n",
    "    ax.set_xticklabels(np.arange(n))\n",
    "    ax.set_yticklabels(np.arange(m))\n",
    "    ax.set_title(title)\n",
    "    ax.invert_yaxis()\n",
    "    plt.show()\n",
    "\n",
    "def normalize_to_Markov(matrix):\n",
    "    row_sums = matrix.sum(axis=1)\n",
    "    return matrix / row_sums[:, np.newaxis]\n",
    "    \n",
    "def eigen(affinity):\n",
    "    #change to computer for symmetrix matrix and convert?\n",
    "    #is absolute value necessary? correct? won't fractoinal powers cause trouble?\n",
    "    evals, evecs = np.linalg.eig(normalize_to_Markov(affinity))\n",
    "    order = np.argsort(np.abs(evals))[::-1]\n",
    "    return evals[order], evecs[:,order]\n",
    "\n",
    "def diffusion_distances(evals, evecs, t = None):\n",
    "    if not t:\n",
    "        t = 1 / (1-evals[1])\n",
    "    n_groups = len(evals)\n",
    "    scaled_evecs = evecs[:,1:] * evals[1:]**t  #check that this works as expected\n",
    "    dd_matrix = np.zeros((n_groups,n_groups))\n",
    "    for i in xrange(n_groups):\n",
    "        dd_matrix[i,i]=0\n",
    "        for j in xrange(i+1, n_groups):\n",
    "            difference = scaled_evecs[i,:] - scaled_evecs[j,:]\n",
    "            dd_matrix[i,j] = np.sqrt(np.dot(difference,difference))\n",
    "    return dd_matrix + dd_matrix.T\n",
    "\n",
    "def plot_diffusion(evals, evecs, t=None, bound=None, title='Diffusion', color=None):\n",
    "    if not t:\n",
    "        t = 1 / (1-evals[1])\n",
    "    x = evecs[:,1]*(evals[1]**t)\n",
    "    y = evecs[:,2]*(evals[2]**t)\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "    lib_nums = library_nums(libraries)\n",
    "    ax.scatter(x, y, color=color)\n",
    "    ax.set_title(title)\n",
    "    if bound:\n",
    "        ax.set_xlim(-bound,bound)\n",
    "        ax.set_ylim(-bound,bound)\n",
    "    plt.show()\n",
    "\n",
    "def plot_diffusion_3d(evals, evecs, t=None, bound=None, title='Diffusion', color=None):\n",
    "    if not t:\n",
    "        t = 1 / (1-evals[1])\n",
    "    x = evecs[:,1]*(evals[1]**t)\n",
    "    y = evecs[:,2]*(evals[2]**t)\n",
    "    z = evecs[:,3]*(evals[3]**t)\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111,projection=\"3d\")\n",
    "    ax.scatter3D(x, y, z, color = color)\n",
    "    ax.set_title(title)\n",
    "    if bound:\n",
    "        ax.set_xlim3d(-bound,bound)\n",
    "        ax.set_ylim3d(-bound,bound)\n",
    "        ax.set_zlim3d(-bound,bound)\n",
    "    plt.show()\n",
    "\n",
    "def scatter_affinities(affinities, lib_matrices, pair_colors, log_scale = False, title='Scatter'):   \n",
    "    fig = plt.figure(figsize=(10,8))\n",
    "    xs = np.arange(len(pair_colors))\n",
    "    plt.scatter(xs, affinities, s=2, color = pair_colors)\n",
    "    plt.title(title)\n",
    "    plt.ylim(1e-6,1)\n",
    "    if log_scale == True:\n",
    "        plt.yscale('log')\n",
    "    for i in xs:\n",
    "        if lib_matrices[i] == 3:\n",
    "            plt.axvline(x=i,ls='-',alpha = .5,c='g',linewidth=1,)\n",
    "    plt.show()\n",
    "    \n",
    "def plot_graph(matrix, threshold, color=None, complement = False):\n",
    "    print 'Threshold =', threshold #include this in title\n",
    "    n_groups = matrix.shape[0]\n",
    "    labels = dict(zip(range(n_groups),range(n_groups)))\n",
    "    if complement:\n",
    "        G = nx.Graph(matrix < threshold)\n",
    "    else:\n",
    "        G = nx.Graph(matrix >= threshold)\n",
    "    pos=nx.spring_layout(G)\n",
    "    nx.draw_networkx_nodes(G,pos,node_color=color)\n",
    "    nx.draw_networkx_edges(G,pos)\n",
    "    nx.draw_networkx_labels(G,pos,labels=labels,font_color='w',font_size=16)\n",
    "    plt.show()\n",
    "    \n",
    "def bool_to_color(x):\n",
    "    if x == True:\n",
    "        return 'b'\n",
    "    elif x == False:\n",
    "        return 'r'\n",
    "    else:\n",
    "        return 'w'\n",
    "\n",
    "# Some snippets from other J Bloom functions, which I found interesting\n",
    "# pair_colors = np.vectorize(bool_to_color)(lib_matrices)\n",
    "# np.set_printoptions(precision=1, suppress=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bradscratch stuff below here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Data reading and distance calculation utilities\n",
    "def read_metadata(meta_file):\n",
    "    with open(meta_file, 'r') as f:\n",
    "        my_json = json.loads(f.read())\n",
    "    return {json.loads(key): value for (key, value) in my_json.iteritems()}\n",
    "\n",
    "def read_table(table_file):\n",
    "    with open(table_file, 'r') as f:\n",
    "        # This will initially read the keys in the k:v pairs as just strings\n",
    "        my_json = json.loads(f.read())\n",
    "    # Convert keys string->list; but cannot hash on a list, so conver to a tuple for use in the map\n",
    "    return {tuple(json.loads(key)): value for (key, value) in my_json.iteritems()}\n",
    "\n",
    "def get_groups_and_libraries(meta):\n",
    "    groups = []\n",
    "    libraries = []\n",
    "    for key in meta.keys():\n",
    "        libraries.append(meta[key]['mAttributes']['LB'])\n",
    "        groups.append(meta[key]['mReadGroupId'])\n",
    "    return (groups, libraries)\n",
    "\n",
    "def package_and_sort(matrix, groups, libraries):\n",
    "    arrays = [np.array(groups), np.array(libraries)]\n",
    "#     df = pd.DataFrame(matrix, index=arrays, columns=arrays).sort_index(level=1).sort_index(level=1, axis=1)\n",
    "    df = pd.DataFrame(matrix, index=arrays, columns=arrays).sortlevel(level=1).sortlevel(level=1, axis=1)\n",
    "    df.index.names=[\"group\", \"library\"]\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting the truth\n"
     ]
    }
   ],
   "source": [
    "# Getting the truth matrix after precomputing the distances.\n",
    "# Because this can be cached too, but is faster to get\n",
    "# Also more frequesnt to change\n",
    "# Therefore helps to be lower down in the stack\n",
    "def make_truth_matrix(groups, libraries):\n",
    "    n_groups = len(groups)\n",
    "    truth = np.zeros((n_groups,n_groups))\n",
    "    for i in xrange(n_groups):\n",
    "        for j in xrange(n_groups):\n",
    "            if i == j:\n",
    "                truth[i,j] = -1  # sentinal value so the diagonal doesn't bias with evaluation metrics\n",
    "            elif libraries[i] == libraries[j]:\n",
    "                truth[i,j] = 1\n",
    "    return package_and_sort(truth, groups, libraries)\n",
    "\n",
    "print \"Getting the truth\"\n",
    "# truth = make_truth_matrix(groups, libraries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Funcions supporting a likelihoods ratio test.\n",
    "def fit_beta_distributions(distance, truth):\n",
    "    # In practice my true-diff-library values are often all 0.0. Faux counts save my true-different beta dist from being entilely 0.\n",
    "    faux_counts = [0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9] \n",
    "    \n",
    "    # Fit a beta distribution to the true positives\n",
    "    true_positives=np.append(distance.values[truth.values>0], faux_counts)\n",
    "    \n",
    "    alphaT, betaT, locT, scaleT = beta.fit(true_positives, floc=0, fscale=1)\n",
    "    dPos = beta(alphaT, betaT, locT, scaleT) # \"freeze\" the distribution parameters as an object\n",
    "\n",
    "    # Fit a beta distribution to the true negatives\n",
    "    true_negatives=np.append(distance.values[truth.values==0] + 10**-27, faux_counts)\n",
    "    print true_negatives\n",
    "    alphaN, betaN, locN, scaleN = beta.fit(true_negatives, floc=0, fscale=1)\n",
    "    dNeg = beta(alphaN, betaN, locN, scaleN)\n",
    "    return {'positive': dPos, 'negative': dNeg}\n",
    "\n",
    "# Likelihood ratio test.\n",
    "def calculate_log_likelihoods_ratio(x, distributions):\n",
    "    dPos = distributions['positive']\n",
    "    dNeg = distributions['negative']\n",
    "    LLalt = np.log(dPos.pdf(x)) # log likelihood that our 'same-library' distribution is the best model given x, i.e. log probability-denisity-function(x) given same-library model\n",
    "    LLnull = np.log(dNeg.pdf(x)) # log likelihood that our 'different-library' distribution is the best model\n",
    "    LLratio = LLalt - LLnull\n",
    "    return LLratio\n",
    "\n",
    "def calculate_log_LLR_probability(x, distributions):\n",
    "    LLR = calculate_log_odds_ratio(x, distributions)\n",
    "    test_statistic = 2*LLR # test statistic follows chi-square distribution with degrees of freedom 0 (since # parameters equal)\n",
    "    return chisqprob(test_statistic, 1) # TODO - I get NaN when DF = 0!!!\n",
    "\n",
    "def LLR_is_significant(x, distributions):\n",
    "    return (calculate_log_LLR_probability(x, distributions) < 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Evaluation function + utilities\n",
    "def summarize_result(result, expected, n_groups):\n",
    "    all_positives = result[expected > 0]\n",
    "    true_positives = all_positives.sum() \n",
    "    true_positive_rate = true_positives / len(all_positives)\n",
    "\n",
    "    all_negatives = result[expected == 0]\n",
    "    true_negatives = len(all_negatives) - all_negatives.sum()\n",
    "    true_negative_rate = true_negatives / len(all_negatives)\n",
    "\n",
    "    total_pairs = (n_groups * n_groups) - n_groups # exclude self-self pairs\n",
    "    rand_index = (true_positives + true_negatives) / total_pairs\n",
    "    \n",
    "    labels = [\"p(same-library | truly same-library)\", \"p(different-library | truly different-library)\", \"Rand index\"]\n",
    "    return pd.DataFrame([true_positive_rate, true_negative_rate, rand_index], index=labels, columns=[\"Value\"])\n",
    "\n",
    "def plot_distance_histogram(distances, dists, truth):\n",
    "    same_distances = distances.values[truth>0]\n",
    "    diff_distances = distances.values[truth==0]\n",
    "    dPos = dists['positive']\n",
    "    dNeg = dists['negative']\n",
    "\n",
    "    # Plot histogram barchars for same-library and different-library distances\n",
    "    my_bins=np.arange(-0.01,1,.01)\n",
    "    plt.hist(same_distances, normed=True, bins=my_bins, alpha=0.5, label='Same-library')\n",
    "    plt.hist(diff_distances, normed=True, bins=my_bins, alpha=0.5, label='Different-library')\n",
    "    \n",
    "    # Add beta function pdf for same-library and different-library models\n",
    "    x = np.linspace(dPos.ppf(0), dPos.ppf(0.99), 100)\n",
    "    plt.plot(x, dPos.pdf(x), 'r', lw=3, alpha=0.6)\n",
    "    plt.plot(x, dNeg.pdf(x), 'b', lw=3, alpha=0.8)\n",
    "    \n",
    "    plt.ylim(ymax=40)\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.title('Distribution of Pairwise Distances')\n",
    "    plt.show()\n",
    "\n",
    "def is_greater_than(x, threshold):\n",
    "    return 1 if x > threshold else 0\n",
    "\n",
    "apply_threshold = np.vectorize(is_greater_than)\n",
    "\n",
    "def get_false_calls(distances, truth, results, n_groups):\n",
    "    false_positives = []\n",
    "    false_negatives = []\n",
    "    for i in xrange(n_groups):\n",
    "        for j in xrange(i, n_groups):\n",
    "            obs = results[i, j]\n",
    "            exp = truth.values[i, j]\n",
    "            dist = distances.values[i,j]\n",
    "            if i != j:\n",
    "                if obs > exp:\n",
    "                    false_positives.append([i, j, obs, exp, distances.index[i], distances.index[j], dist])\n",
    "                elif obs < exp:\n",
    "                    false_negatives.append([i, j, obs, exp, distances.index[i], distances.index[j], dist])\n",
    "    return (false_positives, false_negatives)\n",
    "\n",
    "# Primary evaluation function\n",
    "def evaluate(distances, truth, threshold, n_groups):\n",
    "    display(HTML('<h5>Max distance</h5>'))\n",
    "    print np.max(distances.values)\n",
    "    \n",
    "    result = apply_threshold(distances, threshold)\n",
    "    false_pos, false_neg = get_false_calls(distances, truth, result, n_groups)\n",
    "    \n",
    "    distributions = fit_beta_distributions(distances, truth)\n",
    "    LLR_matrix = get_log_likeihoods(distances, distributions)\n",
    "    LLR_significance = LLR_is_significant(distances, distributions)\n",
    "    LLR_false_pos, LLR_false_neg = get_false_calls(distances, truth, LLR_significance, n_groups)\n",
    "     \n",
    "    display(HTML('<h5>Threshold Evaluation Metrics</h5>'))\n",
    "    display(summarize_result(result, truth.values, n_groups))\n",
    "    display(HTML('<h5>Log-Likelihood Ratio Test Evaluation Metrics</h5>'))\n",
    "    display(summarize_result(LLR_significance, truth.values, n_groups))\n",
    "    display(HTML('<h5>Threshold False Positives</h5>'))\n",
    "    for fp in false_pos: print fp\n",
    "    display(HTML('<h5>Log-Likelihood Ratio Test False Positives</h5>'))\n",
    "    for fp in LLR_false_pos: print fp\n",
    "    display(HTML('<h5>Threshold False Negatives</h5>'))\n",
    "    for fn in false_neg: print fn\n",
    "    display(HTML('<h5>Log-Likelihood Ratio Test Negatives</h5>'))\n",
    "    for fn in LLR_false_neg: print fn\n",
    "    plot_matrix(distances, title='Pairwise Similarity Values')\n",
    "    plot_matrix(result, title='test: Similarity Exceeds Threshold')\n",
    "    plot_matrix(LLR_matrix, title='Log Likelihood Ratios (alt / null)')\n",
    "    plot_matrix(LLR_significance, title='LLR test p-value < 0.05')\n",
    "    plot_distance_histogram(distances, distributions, truth.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# threshold getter functions\n",
    "\n",
    "# TODO - what if min <= max????\n",
    "def min_max_mean(distances, truth):\n",
    "    all_positives = distances.values[truth > 0]\n",
    "    all_negatives = distances.values[truth == 0]\n",
    "    return np.mean([min(all_positives), max(all_negatives)])\n",
    "\n",
    "def exhaustive_search(distances, truth):\n",
    "    n_groups = len(distances.index.values)\n",
    "    sorted_dists = np.sort(np.unique(distances.values))\n",
    "    max_rand_index = 0\n",
    "    max_rand = 0.0\n",
    "    for index in xrange(len(sorted_dists)):\n",
    "        results = apply_threshold(distances, sorted_dists[index])\n",
    "        rand = summarize_result(results, truth, n_groups).loc[\"Rand index\"].values[0]\n",
    "        if rand > max_rand: max_rand_index = index\n",
    "    return sorted_dists[max_rand_index]\n",
    "    \n",
    "# Generic outer function - Dont think I need\n",
    "# def get_threshold(distances, truth, threshold_func):\n",
    "#     return threshold_func(distances, truth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# exhaustive_search(ap_distance, truth)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Perform the experiment\n",
    "def run_experiment(distances, n_groups, distance_label, truth, get_threshold, combine_threshold, evaluate_subsets):\n",
    "    \n",
    "    display(HTML(\"<h3>Evaluating similarity function: {0}</h3>\".format(distance_label)))\n",
    "    display(HTML(\"<h3>Threshold function: {0} | Threshold combiner: {1}</h3>\".format(get_threshold.__name__, combine_threshold.__name__)))\n",
    "    \n",
    "    # perform 5-fold cross-validation\n",
    "    thresholds = []\n",
    "    kf = KFold(n_groups, n_folds=5, shuffle=False)\n",
    "    subset_count = 1\n",
    "    for train, test in kf:\n",
    "        # Select the training distance/truth values\n",
    "        train_dists = distances.iloc[train, train]\n",
    "        train_truth = truth.iloc[train, train]\n",
    "        \n",
    "        # Derive the subset-threshold\n",
    "        threshold = get_threshold(train_dists, train_truth.values)\n",
    "        thresholds.append(threshold)\n",
    "        \n",
    "        # Select the training distance/truth values, and evaluate the threshold\n",
    "        if evaluate_subsets:\n",
    "            # Provide some context on the subset, threshold, evaluations\n",
    "            display(HTML(\"<h4>Evaluating Subset {}</h4>\".format(subset_count)))\n",
    "            print \"Training subset indices\"\n",
    "            print train\n",
    "            print \"Testing subset indices\"\n",
    "            print test\n",
    "            display(HTML(\"<h5>Subset Threshold = {0:.2f}</h5>\".format(round(threshold,2))))\n",
    "            \n",
    "            # Select the test distance/truth values for performance evaluation purposes\n",
    "            test_dists = distances.iloc[test, test]\n",
    "            test_truth = truth.iloc[test, test]\n",
    "            evaluate(test_dists, test_truth, threshold, len(test))\n",
    "        subset_count += 1\n",
    "\n",
    "    # Combine partition level thresholds via provided function\n",
    "    combined_threshold = combine_threshold(thresholds)\n",
    "    display(HTML(\"<h3>Evaluating combined threshold</h3>\"))\n",
    "    display(HTML(\"<h4>Combined Threshold = {0:.2f}</h4>\".format(round(combined_threshold,2))))\n",
    "    \n",
    "    # DISPLAY SUMMARY INFO ABOUT THE THRESHOLD- see pandas dataframe summarize\n",
    "    display(pd.Series(thresholds))\n",
    "    \n",
    "    # Evaluate combined threshold over entire dataset\n",
    "    evaluate(distances, truth, combined_threshold, n_groups)\n",
    "    display(HTML(\"<hr>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Run experiment only on all-pairs affinity to test various threshold getters. Evaluate intermediates to see the process of building the threshold\n",
    "# ap_distance = pd.read_csv(\"test_10_libraries.ap_affinity.csv\", header=[0,1], index_col=[0,1])\n",
    "\n",
    "# threshold_getters = [min_max_mean, exhaustive_search]\n",
    "# for threshold_getter in threshold_getters:\n",
    "#     run_experiment(ap_distance, \"All Pairs Affinity\", groups, truth, threshold_getter, np.mean, True)    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "def limited_pairs(table, n_groups, k):\n",
    "    '''Returns matrix where M[i,j] is count of matching pairs of distinct reads\n",
    "       from groups i and j, up to a certain read type size k (symmetrized).'''\n",
    "    lp_matrix = np.zeros((n_groups,n_groups))\n",
    "    for item in table.items():\n",
    "        if len(item) <= k:\n",
    "            l = len(item[0])\n",
    "            for i in xrange(l-1):\n",
    "                for j in xrange(i+1,l):\n",
    "                    lp_matrix[item[0][i],item[0][j]] += item[1]\n",
    "    return (lp_matrix + np.tril(lp_matrix.T))/2\n",
    "\n",
    "\n",
    "def random_pairs(table, n_groups):\n",
    "    '''Returns matrix where M[i,j] is count of each read type assigned to the \n",
    "       random group i,j drawn from the larger read type (symmetrized).'''\n",
    "    rp_matrix = np.zeros((n_groups, n_groups))\n",
    "    faf = np.zeros((n_groups, n_groups))\n",
    "    for item in table.items():#[:6]:\n",
    "        tup = item[0]\n",
    "        if len(tup) > 1:\n",
    "            pair = np.random.choice(tup, size=2, replace=False)\n",
    "            rp_matrix[min(pair), max(pair)] += item[1]\n",
    "    return (rp_matrix + np.tril(rp_matrix.T))/2\n",
    "\n",
    "def random_pairs_affinity(table, n_groups):\n",
    "    return normalize_by_diagonal(random_pairs(table, n_groups))\n",
    "\n",
    "def unlimited_affinity(table, n_groups):\n",
    "    return normalize_by_diagonal(limited_pairs(table, n_groups, maxint))\n",
    "\n",
    "def ten_limited_affinity(table, n_groups):\n",
    "    return normalize_by_diagonal(limited_pairs(table, n_groups, 10))\n",
    "\n",
    "def five_limited_affinity(table, n_groups):\n",
    "    return normalize_by_diagonal(limited_pairs(table, n_groups, 5))\n",
    "\n",
    "def four_limited_affinity(table, n_groups):\n",
    "    return normalize_by_diagonal(limited_pairs(table, n_groups, 4))\n",
    "\n",
    "def three_limited_affinity(table, n_groups):\n",
    "    return normalize_by_diagonal(limited_pairs(table, n_groups, 3))\n",
    "\n",
    "def two_limited_affinity(table, n_groups):\n",
    "    return normalize_by_diagonal(limited_pairs(table, n_groups, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# rp_affinity = random_pairs_affinity(table, len(groups))\n",
    "# ten_limit = ten_limited_affinity(table, len(groups))\n",
    "# five_limit = five_limited_affinity(table, len(groups))\n",
    "# four = package_and_sort(zero_diag(four_limited_affinity(table, len(groups))), groups, libraries)\n",
    "# three = package_and_sort(zero_diag(three_limited_affinity(table, len(groups))), groups, libraries)\n",
    "# two = package_and_sort(zero_diag(two_limited_affinity(table, len(groups))), groups, libraries)\n",
    "# rp = package_and_sort(zero_diag(rp_affinity), groups, libraries)\n",
    "# ten = package_and_sort(zero_diag(ten_limit), groups, libraries)\n",
    "# five = package_and_sort(zero_diag(five_limit), groups, libraries)\n",
    "# print \"done\"\n",
    "\n",
    "# things = { \"Random Pairs Affinity\": rp, \"Ten Limited All Pairs\": ten, \"Five Limited All Pairs\": five , \"Four limited\": four, \"Three Limited\": three, \"Two Limited\": two}\n",
    "\n",
    "# for test_label, distance in things.iteritems():\n",
    "#     run_experiment(distance, test_label, truth, min_max_mean, np.mean, False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# np.sum(truth.values[truth.values>0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def evaluate_all_distances(distance_files, metadata_file):\n",
    "    meta = read_metadata(metadata_file)\n",
    "    groups, libraries = get_groups_and_libraries(meta)\n",
    "    truth = make_truth_matrix(groups, libraries)\n",
    "    display(HTML(\"<h4>Truth Matrix</h4>\"))\n",
    "    plot_matrix(truth)\n",
    "\n",
    "    \n",
    "    for test_label, test_file in distance_files.iteritems():\n",
    "        distance = pd.read_csv(test_file, header=[0,1], index_col=[0,1])\n",
    "#     print test_label, \n",
    "#     print np.sum(distance.values),    \n",
    "#     print 100 * (np.sum(distance.values) / 798.0),\n",
    "#     print np.max(distance.values)\n",
    "        run_experiment(distance, len(groups), test_label, truth, min_max_mean, np.mean, False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>Truth Matrix</h4>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAVgAAAEKCAYAAABXKk28AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11256f450>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Evaluating similarity function: Ten limited Affinity</h3>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Threshold function: min_max_mean | Threshold combiner: mean</h3>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Evaluating combined threshold</h3>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h4>Combined Threshold = 0.14</h4>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0    0.126143\n",
       "1    0.145811\n",
       "2    0.197309\n",
       "3    0.126143\n",
       "4    0.126143\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h5>Max distance</h5>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.809630607371\n",
      "[  1.00000000e-27   1.00000000e-27   1.00000000e-27 ...,   7.00000000e-01\n",
      "   8.00000000e-01   9.00000000e-01]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "global name 'get_log_likeihoods' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-e89eb536870c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mten_libraries_metadata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"test_10_libraries.read_groups.json\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mevaluate_all_distances\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mten_libraries_distances\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mten_libraries_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-15-3c52cfc2e48c>\u001b[0m in \u001b[0;36mevaluate_all_distances\u001b[0;34m(distance_files, metadata_file)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m#     print 100 * (np.sum(distance.values) / 798.0),\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m#     print np.max(distance.values)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mrun_experiment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdistance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgroups\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_label\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtruth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_max_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-10-c9c0371c7a20>\u001b[0m in \u001b[0;36mrun_experiment\u001b[0;34m(distances, n_groups, distance_label, truth, get_threshold, combine_threshold, evaluate_subsets)\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0;31m# Evaluate combined threshold over entire dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m     \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdistances\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtruth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcombined_threshold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_groups\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m     \u001b[0mdisplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mHTML\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"<hr>\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-0fd6ad2e8bd7>\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(distances, truth, threshold, n_groups)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0mdistributions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_beta_distributions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdistances\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtruth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m     \u001b[0mLLR_matrix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_log_likeihoods\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdistances\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdistributions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0mLLR_significance\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLLR_is_significant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdistances\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdistributions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[0mLLR_false_pos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLLR_false_neg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_false_calls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdistances\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtruth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLLR_significance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_groups\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: global name 'get_log_likeihoods' is not defined"
     ]
    }
   ],
   "source": [
    "# Run experiment on various distance functions with a chosen descriminator, combiner (don't worry about intermediate evaluations)\n",
    "\n",
    "# various precomputed distances from an out-of-notebook script using the same functions as above for file reading, distance computation.\n",
    "#     Then calling to_csv on the resulting pandas dataframes\n",
    "ten_libraries_distances = { \\\n",
    "              \"All Pairs Affinity\" : \"test_10_libraries.ap_affinity.csv\", \\\n",
    "              \"Exact Pairs Affinity\" : \"test_10_libraries.ep_affinity.csv\", \\\n",
    "              \"Jaccard Similarity Index\" : \"test_10_libraries.jaccard.csv\", \\\n",
    "              \"Cosine Similarity\" : \"test_10_libraries.cosine.csv\", \\\n",
    "              \"Random Pairs Affinity\" : \"test_10_libraries.random.csv\" , \\\n",
    "              \"Unlimited Pairs Affinity\" : \"test_10_libraries.unlimited.csv\", \\\n",
    "              \"Ten limited Affinity\" : \"test_10_libraries.ten.csv\", \\\n",
    "              \"Five limited Affinity\" : \"test_10_libraries.five.csv\", \\\n",
    "              \"Four limited Affinity\" : \"test_10_libraries.four.csv\", \\\n",
    "              \"Three limited Affinity\" : \"test_10_libraries.three.csv\", \\\n",
    "              \"Two limited Affinity\" : \"test_10_libraries.two.csv\" \\\n",
    "             }\n",
    "\n",
    "ten_libraries_metadata = \"test_10_libraries.read_groups.json\"\n",
    "\n",
    "evaluate_all_distances(ten_libraries_distances, ten_libraries_metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Run experiment on various distance functions with a chosen descriminator, combiner (don't worry about intermediate evaluations)\n",
    "\n",
    "# various precomputed distances from an out-of-notebook script using the same functions as above for file reading, distance computation.\n",
    "#     Then calling to_csv on the resulting pandas dataframes\n",
    "\n",
    "# Jon Blooms original data- exome libraries only\n",
    "\n",
    "ten_libraries_distances = { \\\n",
    "              \"All Pairs Affinity\" : \"test_exome_libraries.ap_affinity.csv\", \\\n",
    "              \"Exact Pairs Affinity\" : \"test_exome_libraries.ep_affinity.csv\", \\\n",
    "              \"Jaccard Similarity Index\" : \"test_exome_libraries.jaccard.csv\", \\\n",
    "              \"Cosine Similarity\" : \"test_exome_libraries.cosine.csv\", \\\n",
    "              \"Random Pairs Affinity\" : \"test_exome_libraries.random.csv\" , \\\n",
    "              \"Unlimited Pairs Affinity\" : \"test_exome_libraries.unlimited.csv\", \\\n",
    "              \"Ten limited Affinity\" : \"test_exome_libraries.ten.csv\", \\\n",
    "              \"Five limited Affinity\" : \"test_exome_libraries.five.csv\", \\\n",
    "              \"Four limited Affinity\" : \"test_exome_libraries.four.csv\", \\\n",
    "              \"Three limited Affinity\" : \"test_exome_libraries.three.csv\", \\\n",
    "              \"Two limited Affinity\" : \"test_exome_libraries.two.csv\" \\\n",
    "             }\n",
    "\n",
    "ten_libraries_metadata = \"test_exome_libraries.read_groups.json\"\n",
    "\n",
    "distances = pd.read_csv(ten_libraries_distances[\"Ten limited Affinity\"], header=[0,1], index_col=[0,1])\n",
    "\n",
    "# np.min(distances.value[truth])\n",
    "\n",
    "evaluate_all_distances(ten_libraries_distances, ten_libraries_metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Run experiment on various distance functions with a chosen descriminator, combiner (don't worry about intermediate evaluations)\n",
    "\n",
    "# various precomputed distances from an out-of-notebook script using the same functions as above for file reading, distance computation.\n",
    "#     Then calling to_csv on the resulting pandas dataframes\n",
    "\n",
    "# Jon Blooms original data- exome libraries only\n",
    "\n",
    "ten_libraries_distances = { \\\n",
    "              \"All Pairs Affinity\" : \"test_weird_libraries.ap_affinity.csv\", \\\n",
    "              \"Exact Pairs Affinity\" : \"test_weird_libraries.ep_affinity.csv\", \\\n",
    "              \"Jaccard Similarity Index\" : \"test_weird_libraries.jaccard.csv\", \\\n",
    "              \"Cosine Similarity\" : \"test_weird_libraries.cosine.csv\", \\\n",
    "              \"Random Pairs Affinity\" : \"test_weird_libraries.random.csv\" , \\\n",
    "              \"Unlimited Pairs Affinity\" : \"test_weird_libraries.unlimited.csv\", \\\n",
    "              \"Ten limited Affinity\" : \"test_weird_libraries.ten.csv\", \\\n",
    "              \"Five limited Affinity\" : \"test_weird_libraries.five.csv\", \\\n",
    "              \"Four limited Affinity\" : \"test_weird_libraries.four.csv\", \\\n",
    "              \"Three limited Affinity\" : \"test_weird_libraries.three.csv\", \\\n",
    "              \"Two limited Affinity\" : \"test_weird_libraries.two.csv\" \\\n",
    "             }\n",
    "\n",
    "ten_libraries_metadata = \"test_weird_libraries.read_groups.json\"\n",
    "\n",
    "# evaluate_all_distances(ten_libraries_distances, ten_libraries_metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Run experiment on various distance functions with a chosen descriminator, combiner (don't worry about intermediate evaluations)\n",
    "\n",
    "# various precomputed distances from an out-of-notebook script using the same functions as above for file reading, distance computation.\n",
    "#     Then calling to_csv on the resulting pandas dataframes\n",
    "\n",
    "# Jon Blooms original data- exome libraries only\n",
    "\n",
    "ten_libraries_distances = { \\\n",
    "              \"All Pairs Affinity\" : \"test_agilent_libraries.ap_affinity.csv\", \\\n",
    "              \"Exact Pairs Affinity\" : \"test_agilent_libraries.ep_affinity.csv\", \\\n",
    "              \"Jaccard Similarity Index\" : \"test_agilent_libraries.jaccard.csv\", \\\n",
    "              \"Cosine Similarity\" : \"test_agilent_libraries.cosine.csv\", \\\n",
    "              \"Random Pairs Affinity\" : \"test_agilent_libraries.random.csv\" , \\\n",
    "              \"Unlimited Pairs Affinity\" : \"test_agilent_libraries.unlimited.csv\", \\\n",
    "              \"Ten limited Affinity\" : \"test_agilent_libraries.ten.csv\", \\\n",
    "              \"Five limited Affinity\" : \"test_agilent_libraries.five.csv\", \\\n",
    "              \"Four limited Affinity\" : \"test_agilent_libraries.four.csv\", \\\n",
    "              \"Three limited Affinity\" : \"test_agilent_libraries.three.csv\", \\\n",
    "              \"Two limited Affinity\" : \"test_agilent_libraries.two.csv\" \\\n",
    "             }\n",
    "\n",
    "ten_libraries_metadata = \"test_agilent_libraries.read_groups.json\"\n",
    "\n",
    "evaluate_all_distances(ten_libraries_distances, ten_libraries_metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# meta = read_metadata(ten_libraries_metadata)\n",
    "# for (numb, read_group) in meta.iteritems():\n",
    "#     print numb, read_group[u'mReadGroupId'], read_group['mAttributes']['LB']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Read in the data and precompute distance\n",
    "# Just splitting this off to cache the values\n",
    "print \"Reading inputs\"\n",
    "# meta = read_metadata('test_2_libraries.tabledata.json.read_groups.json')\n",
    "# table = read_table('test2libs.tabledata.json')  \n",
    "\n",
    "# meta = read_metadata('test_10_libraries.read_groups.json')\n",
    "# table = read_table('test_10_libraries.table.json')\n",
    "\n",
    "meta = read_metadata('test_exome_libraries.read_groups.json')\n",
    "table = read_table('test_exome_libraries.table.json')  \n",
    "\n",
    "groups, libraries = get_groups_and_libraries(meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print \"Calculating pairwise distances\"\n",
    "# ap_affinity = package_and_sort(zero_diag(all_pairs_affinity(table, len(groups))), groups, libraries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print \"calculating fixed distances\"\n",
    "# ap_affinity_fixed = package_and_sort(zero_diag(all_pairs_affinity_fixed(table, len(groups))), groups, libraries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def all_pairs_affinity(table, n_groups):\n",
    "    return normalize_by_diagonal(all_pairs_fixed(table, n_groups))\n",
    "\n",
    "def all_pairs_fixed(table, n_groups):\n",
    "    '''Returns matrix where M[i,j] is count of matching pairs of distinct reads\n",
    "       from groups i and j (symmetrized).'''\n",
    "    ap_matrix = np.zeros((n_groups,n_groups))\n",
    "    for item in table.items():\n",
    "        l = len(item[0])\n",
    "        for i in xrange(l-1):\n",
    "            for j in xrange(i+1,l):\n",
    "                ap_matrix[item[0][i],item[0][j]] += item[1]\n",
    "    return (ap_matrix + np.tril(ap_matrix.T) + np.diagonal(ap_matrix))/2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "groups, libraries = get_groups_and_libraries(meta)\n",
    "n_groups = len(groups)\n",
    "ap_matrix = np.zeros((n_groups,n_groups))\n",
    "for item in table.items():\n",
    "    l = len(item[0])\n",
    "    for i in xrange(l-1):\n",
    "        for j in xrange(i+1,l):\n",
    "            ap_matrix[item[0][i],item[0][j]] += item[1]\n",
    "\n",
    "            \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "            \n",
    "plot_matrix(ap_matrix)\n",
    "print ap_matrix[0,0]\n",
    "plot_matrix(ap_matrix.T)\n",
    "print ap_matrix.T[0,0]\n",
    "plot_matrix(np.tril(ap_matrix.T))\n",
    "print np.tril(ap_matrix.T)[0,0]\n",
    "plot_matrix(ap_matrix + np.tril(ap_matrix.T))\n",
    "print (ap_matrix + np.tril(ap_matrix.T))[0,0]\n",
    "raw = (ap_matrix + np.tril(ap_matrix.T))/2\n",
    "plot_matrix((ap_matrix + np.tril(ap_matrix.T))/2)\n",
    "((ap_matrix + np.tril(ap_matrix.T))/2)[0,0]\n",
    "orig = normalize_by_diagonal(((ap_matrix + np.tril(ap_matrix.T))/2))\n",
    "plot_matrix(normalize_by_diagonal(((ap_matrix + np.tril(ap_matrix.T))/2)))\n",
    "print normalize_by_diagonal(((ap_matrix + np.tril(ap_matrix.T))/2))[0,0]\n",
    "np.max(normalize_by_diagonal(((ap_matrix + np.tril(ap_matrix.T))/2)))\n",
    "print orig[10,13]\n",
    "\n",
    "def normalize_by_diagonal2(matrix):\n",
    "    diag = 2 * np.diagonal(matrix)\n",
    "    return matrix / np.sqrt(np.outer(diag, diag))\n",
    "\n",
    "plot_matrix(normalize_by_diagonal2(((ap_matrix + np.tril(ap_matrix.T))/2)))\n",
    "floof = normalize_by_diagonal2(((ap_matrix + np.tril(ap_matrix.T))/2))\n",
    "print floof[0,0]\n",
    "np.max(normalize_by_diagonal2(((ap_matrix + np.tril(ap_matrix.T))/2)))\n",
    "print floof[10,13]\n",
    "# ok_some_dists = (package_and_sort(zero_diag(normalize_by_diagonal(((ap_matrix + np.tril(ap_matrix.T))/2))), groups, libraries))\n",
    "\n",
    "# # display(ok_some_dists)\n",
    "# plot_matrix(raw)\n",
    "# plot_matrix(orig)\n",
    "# # plot_matrix(ok_some_dists)\n",
    "# farp = ok_some_dists\n",
    "# farp[ok_some_dists <= 1] = 0\n",
    "# orig[orig <= 1] = 0\n",
    "# plot_matrix(orig)\n",
    "\n",
    "# print orig[10]\n",
    "# print raw[10]\n",
    "# print orig[10,13]\n",
    "# print raw[10,13]\n",
    "\n",
    "# print\n",
    "# print orig[4,5]\n",
    "# print raw[4,5]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# diag = np.diagonal(raw)\n",
    "# print diag\n",
    "# denom = np.sqrt(np.outer(diag, diag))\n",
    "# plot_matrix(raw)\n",
    "# plot_matrix(np.outer(diag,diag))\n",
    "# plot_matrix(denom)\n",
    "# plot_matrix(raw/denom)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "raw = (ap_matrix + np.tril(ap_matrix.T))/2\n",
    "plot_matrix(raw)\n",
    "sortee = package_and_sort(raw, groups, libraries)\n",
    "plot_matrix(sortee)\n",
    "foof = normalize_by_diagonal(sortee.values)\n",
    "plot_matrix(foof)\n",
    "print np.max(foof)\n",
    "\n",
    "\n",
    "diag = np.diagonal(sortee)\n",
    "print diag\n",
    "denom = np.sqrt(np.outer(diag, diag))\n",
    "plot_matrix(np.outer(diag,diag))\n",
    "plot_matrix(denom)\n",
    "plot_matrix(sortee.values/denom)\n",
    "np.max(sortee.values/denom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print sortee.values[10,10]\n",
    "print sortee.values[10,11]\n",
    "print foof[10,10]\n",
    "print foof[10,11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "exacts = exact_pairs_affinity(table, n_groups)\n",
    "print \"woot\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_matrix(exacts)\n",
    "print np.max(zero_diag(exacts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_matrix(ap_matrix)\n",
    "print ap_matrix[10,10]\n",
    "print ap_matrix[10,13]\n",
    "print np.diag(ap_matrix)\n",
    "print np.diag(ap_matrix) * 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
